{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febc81e7-5a06-4cbd-9050-7d9068cf7e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 10:25:18.404158: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-27 10:25:18.443382: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-27 10:25:18.443407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-27 10:25:18.443449: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 10:25:18.452126: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-27 10:25:19.304381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "#Batched compression and pruning\n",
    "\n",
    "class SVDDense(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, mu_ort = 1000, mu_sing = 1, mu_comp = 0.1, prune_threshold = 0.1  , pruning_batch_size = 1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.units = units\n",
    "        self.mu_ort = mu_ort\n",
    "        self.mu_sing = mu_sing\n",
    "        self.mu_comp = mu_comp\n",
    "        self.prune_threshold = prune_threshold\n",
    "        self.rank = 1 #Is replaced later.\n",
    "        self.pruning_batch_size = pruning_batch_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
    "\n",
    "        values = initializer(shape=(input_shape[-1], self.units))\n",
    "\n",
    "        #It is not possible to directly set weights on creation, so for now we're generating them as zeros and calling assign\n",
    "        sigma, u, v = tf.linalg.svd(values, full_matrices=False)\n",
    "        vt = tf.transpose(v)\n",
    "        self.rank = int(tf.shape(sigma)[0])\n",
    "        print(self.rank)\n",
    "\n",
    "        \n",
    "        self.u = self.add_weight(\n",
    "            shape=(input_shape[-1], self.rank), initializer='zeros', trainable=True, name=\"u\"\n",
    "        )\n",
    "        self.u.assign(u)\n",
    "\n",
    "        self.sigma = self.add_weight(\n",
    "            shape=(self.rank,), initializer='zeros', trainable=True, name=\"sigma\"\n",
    "        )\n",
    "        self.sigma.assign(sigma)\n",
    "\n",
    "        self.vt = self.add_weight(\n",
    "            shape=(self.rank, self.units), initializer='zeros', trainable=True, name=\"vt\"\n",
    "        )\n",
    "        self.vt.assign(vt)\n",
    "\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=initializer, trainable=True, name=\"bias\"\n",
    "        )\n",
    "\n",
    "        self.rank = tf.Variable(self.rank, trainable=False, dtype=tf.int32)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        current_u = self.u[:, :self.rank]\n",
    "        current_sigma = self.sigma[:self.rank]\n",
    "        current_vt = self.vt[:self.rank]\n",
    "        #rank_f = tf.cast(self.rank, tf.float32)\n",
    "\n",
    "        \n",
    "        smallest_batch = tf.reduce_sum(current_sigma[-self.pruning_batch_size:])\n",
    "        secondSmallest_batch = tf.reduce_sum(current_sigma[-self.pruning_batch_size*2:-self.pruning_batch_size])\n",
    "\n",
    "        tf.cond(\n",
    "            self.rank > self.pruning_batch_size,\n",
    "            lambda: self.rank.assign(tf.cond(\n",
    "                smallest_batch < self.prune_threshold * secondSmallest_batch,\n",
    "                    lambda: self.rank - self.pruning_batch_size,\n",
    "                    lambda: self.rank\n",
    "            )),\n",
    "            lambda: self.rank\n",
    "        )\n",
    "\n",
    "#         #can_decrease = current_sigma[-1] < self.prune_threshold * sigma[-2]\n",
    "#         #sigma_mask = tf.cast(tf.range(tf.shape(self.sigma)[0]) == (self.rank - 1), tf.float32)\n",
    "#         rank_int = tf.cast(self.rank, tf.int32)\n",
    "#         last_sigma = tf.gather(self.sigma, rank_int - 1)#self.sigma[-1]\n",
    "        \n",
    "        #Calculate loss for this layer\n",
    "        self.add_loss(\n",
    "            #normality loss\n",
    "            self.mu_ort * (\n",
    "                tf.reduce_mean(tf.abs(1-tf.reduce_sum(tf.square(current_vt), axis=0))) + \n",
    "                tf.reduce_mean(tf.abs(1-tf.reduce_sum(tf.square(current_u), axis=1)))\n",
    "            )\n",
    "                #tf.reduce_mean(tf.square(tf.matmul(current_u, current_u, transpose_a=True) - tf.eye(tf.shape(current_sigma)[0]))) + \n",
    "                #tf.reduce_mean(tf.square(tf.matmul(current_vt, current_vt, transpose_b=True) - tf.eye(tf.shape(current_sigma)[0])))\n",
    "            +\n",
    "\n",
    "            #sorting loss\n",
    "            self.mu_sing * (\n",
    "                self.singular_sorting_loss(current_sigma)\n",
    "            )\n",
    "\n",
    "            +\n",
    "\n",
    "            # Compression loss \n",
    "            # Different from the original paper, it simply attempts to further decrease the size of the final (smallest) singular value.\n",
    "            self.mu_comp * smallest_batch        \n",
    "        )\n",
    "        \n",
    "        x = tf.matmul(inputs, current_u)\n",
    "        x = tf.matmul(x, tf.linalg.diag(current_sigma))\n",
    "        x = tf.matmul(x, current_vt)\n",
    "        return x + self.b\n",
    "    \n",
    "    def singular_sorting_loss(self, weights):\n",
    "        difs = weights[1:] - weights[:-1] #The differences of each value and the one after\n",
    "        difsum = tf.math.divide_no_nan(tf.reduce_sum(tf.nn.relu(-difs)), #Sum of negative differences\n",
    "                                       tf.reduce_sum(tf.cast(difs < 0, tf.float32))) #divided by the amount of negative differences (with 0 if dividing by 0)\n",
    "        # sumnegs = tf.math.divide_no_nan(tf.reduce_sum(tf.nn.relu(-weights)),  #Sum of negative weights\n",
    "        #                                 tf.reduce_sum(tf.cast(weights < 0, tf.float32))) #divided by the amount of negative weights (with 0 if dividing by 0)\n",
    "        negs = tf.nn.relu(-weights[-1]) #And a push to keep the final value above 0. \n",
    "        return difsum + negs\n",
    "\n",
    "#Can be created using a finished SVDDense layer. Used to actually decrease the parameter count, and does not prune or compress anymore. \n",
    "class RecomposedDense(keras.layers.Layer):\n",
    "    def __init__(self, units=32, weights = [], b = [], *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.units = units\n",
    "        self.w = weights\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units), initializer=tf.constant_initializer(self.w), trainable=True, name=\"weights\"\n",
    "        )\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=tf.constant_initializer(self.b), trainable=True, name=\"bias\"\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "\n",
    "        #Temp test, try to immediately prune everything but 1\n",
    "        # tf.cond(self.rank > 1, lambda: self.rank.assign_sub(1), lambda: self.rank)\n",
    "\n",
    "        #Calculate loss for this layer\n",
    "#        self.add_loss(0)\n",
    "        x = tf.matmul(inputs, self.w)\n",
    "        return x + self.b\n",
    "    \n",
    "class DecomposedDense(keras.layers.Layer):\n",
    "    def __init__(self, units=32, u_sigma = [], vt = [], b = [], *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.units = units\n",
    "        self.rank = 1 #Overwritten during build.\n",
    "        self.u_sigma = u_sigma\n",
    "        self.vt = vt\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.rank = int(tf.shape(self.u_sigma)[1])\n",
    "\n",
    "        self.u_sigma = self.add_weight(\n",
    "            shape=(input_shape[-1], self.rank), initializer=tf.constant_initializer(self.u_sigma), trainable=True, name=\"u\"\n",
    "        )\n",
    "\n",
    "        if len(self.vt) == 1:\n",
    "           self.vt = self.vt[0][0]\n",
    "\n",
    "        self.vt = self.add_weight(\n",
    "            shape=(self.rank, self.units), initializer=tf.constant_initializer(self.vt), trainable=True, name=\"vt\"\n",
    "            #shape=(int(self.rank), self.units), initializer='zeros', trainable=True, name=\"vt\"\n",
    "        )\n",
    "        #self.vt.assign(vt)\n",
    "\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=tf.constant_initializer(self.b), trainable=True, name=\"bias\"\n",
    "        )\n",
    "\n",
    "        self.rank = tf.Variable(self.rank, trainable=False, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "\n",
    "        #Temp test, try to immediately prune everything but 1\n",
    "        # tf.cond(self.rank > 1, lambda: self.rank.assign_sub(1), lambda: self.rank)\n",
    "\n",
    "        #Calculate loss for this layer\n",
    "#        self.add_loss(0)\n",
    "        x = tf.matmul(inputs, self.u_sigma)\n",
    "        x = tf.matmul(x, self.vt)\n",
    "        return x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478c5d4e-190c-49b9-9a6c-6bfeb085ca94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 10:25:53.247882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1188 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.250904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13285 MB memory:  -> device: 1, name: NVIDIA A16, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.253293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13285 MB memory:  -> device: 2, name: NVIDIA A16, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.255859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13285 MB memory:  -> device: 3, name: NVIDIA A16, pci bus id: 0000:1e:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.258890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 13285 MB memory:  -> device: 4, name: NVIDIA A16, pci bus id: 0000:ce:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.261771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 13285 MB memory:  -> device: 5, name: NVIDIA A16, pci bus id: 0000:cf:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.264780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 13285 MB memory:  -> device: 6, name: NVIDIA A16, pci bus id: 0000:d0:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.267693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 13285 MB memory:  -> device: 7, name: NVIDIA A16, pci bus id: 0000:d1:00.0, compute capability: 8.6\n",
      "2025-06-27 10:25:53.385521: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x555a3ed3a420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " first (SVDDense)            (None, 600)               831601    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 600)               0         \n",
      "                                                                 \n",
      " second (SVDDense)           (None, 300)               270601    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                3010      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1105222 (4.22 MB)\n",
      "Trainable params: 1105210 (4.22 MB)\n",
      "Non-trainable params: 12 (48.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"custom_model/activation_2/Softmax:0\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"custom_model/activation_2/Softmax:0\", shape=(1000, 10), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 10:25:56.993840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f28daf14f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-27 10:25:56.993866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993873: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993879: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993882: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993885: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:56.993888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): NVIDIA A16, Compute Capability 8.6\n",
      "2025-06-27 10:25:57.021323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2025-06-27 10:25:57.153986: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 4s 23ms/step - loss: 23.0936 - cce: 50.1835 - acc: 0.8377 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 6.5250 - val_acc: 0.8894\n",
      "Epoch 2/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 5.5501 - cce: 4.5089 - acc: 0.8762 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 2.9483 - val_acc: 0.8657\n",
      "Epoch 3/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 3.6570 - cce: 2.1534 - acc: 0.8606 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 2.1572 - val_acc: 0.8487\n",
      "Epoch 4/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 2.8514 - cce: 1.1921 - acc: 0.8536 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6078 - val_acc: 0.8625\n",
      "Epoch 5/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 2.3963 - cce: 0.7129 - acc: 0.8477 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.3800 - val_acc: 0.8408\n",
      "Epoch 6/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 2.1586 - cce: 0.4644 - acc: 0.8441 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.3778 - val_acc: 0.8380\n",
      "Epoch 7/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.9996 - cce: 0.3267 - acc: 0.8453 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1780 - val_acc: 0.8620\n",
      "Epoch 8/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.9080 - cce: 0.2396 - acc: 0.8537 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1431 - val_acc: 0.8493\n",
      "Epoch 9/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.8425 - cce: 0.1770 - acc: 0.8581 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0489 - val_acc: 0.8604\n",
      "Epoch 10/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.7813 - cce: 0.1415 - acc: 0.8667 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1564 - val_acc: 0.8713\n",
      "Epoch 11/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.7506 - cce: 0.1273 - acc: 0.8717 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 0.9924 - val_acc: 0.8671\n",
      "Epoch 12/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.7356 - cce: 0.1174 - acc: 0.8812 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1251 - val_acc: 0.8820\n",
      "Epoch 13/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.7022 - cce: 0.0994 - acc: 0.8860 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0512 - val_acc: 0.8730\n",
      "Epoch 14/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6896 - cce: 0.0888 - acc: 0.8915 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0641 - val_acc: 0.8951\n",
      "Epoch 15/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6724 - cce: 0.1019 - acc: 0.9025 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1220 - val_acc: 0.8929\n",
      "Epoch 16/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.6412 - cce: 0.0716 - acc: 0.9006 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0070 - val_acc: 0.8996\n",
      "Epoch 17/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6262 - cce: 0.0765 - acc: 0.9065 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0281 - val_acc: 0.9035\n",
      "Epoch 18/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6052 - cce: 0.0665 - acc: 0.9123 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 0.9692 - val_acc: 0.9094\n",
      "Epoch 19/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.5784 - cce: 0.0595 - acc: 0.9176 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0734 - val_acc: 0.9122\n",
      "Epoch 20/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.5564 - cce: 0.0546 - acc: 0.9200 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 0.9740 - val_acc: 0.9180\n",
      "Epoch 21/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.5442 - cce: 0.0675 - acc: 0.9199 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1088 - val_acc: 0.9154\n",
      "Epoch 22/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.5216 - cce: 0.0545 - acc: 0.9246 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 0.9364 - val_acc: 0.9238\n",
      "Epoch 23/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.4961 - cce: 0.0434 - acc: 0.9306 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 0.9469 - val_acc: 0.9304\n",
      "Epoch 24/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.4897 - cce: 0.0529 - acc: 0.9346 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0579 - val_acc: 0.9301\n",
      "Epoch 25/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.4694 - cce: 0.0571 - acc: 0.9360 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0425 - val_acc: 0.9208\n",
      "Epoch 26/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.4360 - cce: 0.0481 - acc: 0.9408 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0200 - val_acc: 0.9340\n",
      "Epoch 27/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.4084 - cce: 0.0465 - acc: 0.9423 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0883 - val_acc: 0.9319\n",
      "Epoch 28/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.3833 - cce: 0.0477 - acc: 0.9459 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0888 - val_acc: 0.9371\n",
      "Epoch 29/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.3546 - cce: 0.0417 - acc: 0.9471 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1011 - val_acc: 0.9426\n",
      "Epoch 30/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.3235 - cce: 0.0471 - acc: 0.9484 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0525 - val_acc: 0.9382\n",
      "Epoch 31/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.2893 - cce: 0.0436 - acc: 0.9515 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1398 - val_acc: 0.9408\n",
      "Epoch 32/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.2553 - cce: 0.0436 - acc: 0.9566 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0762 - val_acc: 0.9477\n",
      "Epoch 33/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.2181 - cce: 0.0385 - acc: 0.9584 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.2136 - val_acc: 0.9430\n",
      "Epoch 34/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.1936 - cce: 0.0429 - acc: 0.9559 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1304 - val_acc: 0.9448\n",
      "Epoch 35/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.1523 - cce: 0.0364 - acc: 0.9608 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.2241 - val_acc: 0.9523\n",
      "Epoch 36/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.1239 - cce: 0.0518 - acc: 0.9616 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.0587 - val_acc: 0.9501\n",
      "Epoch 37/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.0600 - cce: 0.0305 - acc: 0.9651 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1959 - val_acc: 0.9593\n",
      "Epoch 38/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.0241 - cce: 0.0359 - acc: 0.9679 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1524 - val_acc: 0.9513\n",
      "Epoch 39/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.0073 - cce: 0.0398 - acc: 0.9695 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.1549 - val_acc: 0.9596\n",
      "Epoch 40/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.9440 - cce: 0.0295 - acc: 0.9723 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.2231 - val_acc: 0.9643\n",
      "Epoch 41/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.8828 - cce: 0.0351 - acc: 0.9744 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.3090 - val_acc: 0.9630\n",
      "Epoch 42/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.8089 - cce: 0.0348 - acc: 0.9767 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4454 - val_acc: 0.9680\n",
      "Epoch 43/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.7592 - cce: 0.0477 - acc: 0.9803 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.3935 - val_acc: 0.9710\n",
      "Epoch 44/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6654 - cce: 0.0288 - acc: 0.9822 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4433 - val_acc: 0.9703\n",
      "Epoch 45/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.6146 - cce: 0.0390 - acc: 0.9803 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4042 - val_acc: 0.9694\n",
      "Epoch 46/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5741 - cce: 0.0437 - acc: 0.9814 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4416 - val_acc: 0.9722\n",
      "Epoch 47/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5227 - cce: 0.0400 - acc: 0.9837 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4709 - val_acc: 0.9697\n",
      "Epoch 48/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4761 - cce: 0.0386 - acc: 0.9848 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5295 - val_acc: 0.9756\n",
      "Epoch 49/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.4310 - cce: 0.0326 - acc: 0.9857 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4048 - val_acc: 0.9736\n",
      "Epoch 50/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3724 - cce: 0.0297 - acc: 0.9851 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4908 - val_acc: 0.9748\n",
      "Epoch 51/150\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3081 - cce: 0.0307 - acc: 0.9864 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6279 - val_acc: 0.9755\n",
      "Epoch 52/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2650 - cce: 0.0366 - acc: 0.9885 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5594 - val_acc: 0.9771\n",
      "Epoch 53/150\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2386 - cce: 0.0378 - acc: 0.9892 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5619 - val_acc: 0.9782\n",
      "Epoch 54/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2255 - cce: 0.0336 - acc: 0.9882 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5413 - val_acc: 0.9764\n",
      "Epoch 55/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2203 - cce: 0.0319 - acc: 0.9895 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4861 - val_acc: 0.9791\n",
      "Epoch 56/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2088 - cce: 0.0297 - acc: 0.9905 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4871 - val_acc: 0.9784\n",
      "Epoch 57/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2130 - cce: 0.0271 - acc: 0.9899 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4163 - val_acc: 0.9773\n",
      "Epoch 58/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2107 - cce: 0.0281 - acc: 0.9891 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5146 - val_acc: 0.9793\n",
      "Epoch 59/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2098 - cce: 0.0194 - acc: 0.9898 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4864 - val_acc: 0.9785\n",
      "Epoch 60/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2147 - cce: 0.0317 - acc: 0.9897 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.3668 - val_acc: 0.9791\n",
      "Epoch 61/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2022 - cce: 0.0186 - acc: 0.9904 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4832 - val_acc: 0.9786\n",
      "Epoch 62/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2095 - cce: 0.0288 - acc: 0.9908 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6159 - val_acc: 0.9806\n",
      "Epoch 63/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2066 - cce: 0.0247 - acc: 0.9914 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5718 - val_acc: 0.9805\n",
      "Epoch 64/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2043 - cce: 0.0272 - acc: 0.9914 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5441 - val_acc: 0.9791\n",
      "Epoch 65/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2105 - cce: 0.0330 - acc: 0.9904 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5812 - val_acc: 0.9804\n",
      "Epoch 66/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2131 - cce: 0.0296 - acc: 0.9912 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4902 - val_acc: 0.9796\n",
      "Epoch 67/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2053 - cce: 0.0194 - acc: 0.9909 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6609 - val_acc: 0.9800\n",
      "Epoch 68/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2022 - cce: 0.0222 - acc: 0.9914 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5592 - val_acc: 0.9791\n",
      "Epoch 69/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2017 - cce: 0.0218 - acc: 0.9913 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7022 - val_acc: 0.9814\n",
      "Epoch 70/150\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2070 - cce: 0.0301 - acc: 0.9923 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5744 - val_acc: 0.9824\n",
      "Epoch 71/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2064 - cce: 0.0266 - acc: 0.9921 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7434 - val_acc: 0.9819\n",
      "Epoch 72/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1992 - cce: 0.0140 - acc: 0.9927 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.8219 - val_acc: 0.9817\n",
      "Epoch 73/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2076 - cce: 0.0255 - acc: 0.9919 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7111 - val_acc: 0.9809\n",
      "Epoch 74/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1976 - cce: 0.0227 - acc: 0.9923 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6970 - val_acc: 0.9811\n",
      "Epoch 75/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2061 - cce: 0.0258 - acc: 0.9924 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6704 - val_acc: 0.9827\n",
      "Epoch 76/150\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2140 - cce: 0.0331 - acc: 0.9930 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5284 - val_acc: 0.9820\n",
      "Epoch 77/150\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2012 - cce: 0.0249 - acc: 0.9922 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.8017 - val_acc: 0.9821\n",
      "Epoch 78/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1987 - cce: 0.0245 - acc: 0.9924 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7637 - val_acc: 0.9812\n",
      "Epoch 79/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2032 - cce: 0.0301 - acc: 0.9924 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4797 - val_acc: 0.9833\n",
      "Epoch 80/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1995 - cce: 0.0223 - acc: 0.9934 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6176 - val_acc: 0.9830\n",
      "Epoch 81/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2064 - cce: 0.0305 - acc: 0.9932 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7273 - val_acc: 0.9830\n",
      "Epoch 82/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2025 - cce: 0.0216 - acc: 0.9937 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5961 - val_acc: 0.9833\n",
      "Epoch 83/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1946 - cce: 0.0194 - acc: 0.9928 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4900 - val_acc: 0.9839\n",
      "Epoch 84/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1933 - cce: 0.0171 - acc: 0.9936 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5330 - val_acc: 0.9825\n",
      "Epoch 85/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1996 - cce: 0.0195 - acc: 0.9930 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7964 - val_acc: 0.9826\n",
      "Epoch 86/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1972 - cce: 0.0157 - acc: 0.9937 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6762 - val_acc: 0.9834\n",
      "Epoch 87/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1979 - cce: 0.0149 - acc: 0.9939 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6308 - val_acc: 0.9839\n",
      "Epoch 88/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1925 - cce: 0.0163 - acc: 0.9943 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7551 - val_acc: 0.9840\n",
      "Epoch 89/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1958 - cce: 0.0187 - acc: 0.9943 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7123 - val_acc: 0.9842\n",
      "Epoch 90/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1905 - cce: 0.0109 - acc: 0.9941 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7005 - val_acc: 0.9823\n",
      "Epoch 91/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2008 - cce: 0.0259 - acc: 0.9935 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7830 - val_acc: 0.9825\n",
      "Epoch 92/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1975 - cce: 0.0263 - acc: 0.9940 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5710 - val_acc: 0.9831\n",
      "Epoch 93/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1926 - cce: 0.0104 - acc: 0.9941 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6329 - val_acc: 0.9847\n",
      "Epoch 94/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1927 - cce: 0.0134 - acc: 0.9945 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6254 - val_acc: 0.9839\n",
      "Epoch 95/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2034 - cce: 0.0190 - acc: 0.9937 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5641 - val_acc: 0.9823\n",
      "Epoch 96/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1969 - cce: 0.0229 - acc: 0.9936 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6399 - val_acc: 0.9815\n",
      "Epoch 97/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1977 - cce: 0.0210 - acc: 0.9945 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5779 - val_acc: 0.9839\n",
      "Epoch 98/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1893 - cce: 0.0077 - acc: 0.9950 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6053 - val_acc: 0.9848\n",
      "Epoch 99/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1950 - cce: 0.0194 - acc: 0.9943 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6416 - val_acc: 0.9840\n",
      "Epoch 100/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1884 - cce: 0.0140 - acc: 0.9945 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7745 - val_acc: 0.9811\n",
      "Epoch 101/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.1920 - cce: 0.0152 - acc: 0.9941 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4839 - val_acc: 0.9850\n",
      "Epoch 102/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1964 - cce: 0.0162 - acc: 0.9950 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5512 - val_acc: 0.9847\n",
      "Epoch 103/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1937 - cce: 0.0238 - acc: 0.9949 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7232 - val_acc: 0.9845\n",
      "Epoch 104/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1967 - cce: 0.0187 - acc: 0.9950 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6843 - val_acc: 0.9855\n",
      "Epoch 105/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1945 - cce: 0.0214 - acc: 0.9951 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6285 - val_acc: 0.9847\n",
      "Epoch 106/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.1957 - cce: 0.0178 - acc: 0.9952 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5448 - val_acc: 0.9866\n",
      "Epoch 107/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1913 - cce: 0.0121 - acc: 0.9951 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5237 - val_acc: 0.9853\n",
      "Epoch 108/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1932 - cce: 0.0197 - acc: 0.9952 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5817 - val_acc: 0.9851\n",
      "Epoch 109/150\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.1909 - cce: 0.0152 - acc: 0.9951 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4971 - val_acc: 0.9853\n",
      "Epoch 110/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1898 - cce: 0.0159 - acc: 0.9959 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6661 - val_acc: 0.9851\n",
      "Epoch 111/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1867 - cce: 0.0125 - acc: 0.9957 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7708 - val_acc: 0.9853\n",
      "Epoch 112/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1904 - cce: 0.0161 - acc: 0.9956 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6161 - val_acc: 0.9858\n",
      "Epoch 113/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1834 - cce: 0.0127 - acc: 0.9959 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6281 - val_acc: 0.9862\n",
      "Epoch 114/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1863 - cce: 0.0170 - acc: 0.9958 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7119 - val_acc: 0.9861\n",
      "Epoch 115/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1841 - cce: 0.0077 - acc: 0.9958 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7408 - val_acc: 0.9860\n",
      "Epoch 116/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1867 - cce: 0.0121 - acc: 0.9957 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7590 - val_acc: 0.9850\n",
      "Epoch 117/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1834 - cce: 0.0160 - acc: 0.9964 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7343 - val_acc: 0.9859\n",
      "Epoch 118/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1861 - cce: 0.0187 - acc: 0.9959 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6124 - val_acc: 0.9866\n",
      "Epoch 119/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1775 - cce: 0.0065 - acc: 0.9965 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6515 - val_acc: 0.9868\n",
      "Epoch 120/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1801 - cce: 0.0092 - acc: 0.9964 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5183 - val_acc: 0.9860\n",
      "Epoch 121/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1845 - cce: 0.0138 - acc: 0.9962 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5500 - val_acc: 0.9857\n",
      "Epoch 122/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1835 - cce: 0.0150 - acc: 0.9958 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.4553 - val_acc: 0.9862\n",
      "Epoch 123/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1846 - cce: 0.0137 - acc: 0.9960 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6325 - val_acc: 0.9840\n",
      "Epoch 124/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1932 - cce: 0.0202 - acc: 0.9961 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7548 - val_acc: 0.9854\n",
      "Epoch 125/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1831 - cce: 0.0145 - acc: 0.9959 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5252 - val_acc: 0.9865\n",
      "Epoch 126/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1832 - cce: 0.0145 - acc: 0.9961 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6433 - val_acc: 0.9844\n",
      "Epoch 127/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1800 - cce: 0.0114 - acc: 0.9963 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7946 - val_acc: 0.9864\n",
      "Epoch 128/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1811 - cce: 0.0079 - acc: 0.9962 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5883 - val_acc: 0.9856\n",
      "Epoch 129/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1889 - cce: 0.0188 - acc: 0.9964 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5763 - val_acc: 0.9872\n",
      "Epoch 130/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1830 - cce: 0.0089 - acc: 0.9967 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7168 - val_acc: 0.9867\n",
      "Epoch 131/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1781 - cce: 0.0074 - acc: 0.9967 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5641 - val_acc: 0.9870\n",
      "Epoch 132/150\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.1785 - cce: 0.0091 - acc: 0.9969 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.8323 - val_acc: 0.9880\n",
      "Epoch 133/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1815 - cce: 0.0122 - acc: 0.9966 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7101 - val_acc: 0.9869\n",
      "Epoch 134/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1867 - cce: 0.0136 - acc: 0.9967 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6710 - val_acc: 0.9865\n",
      "Epoch 135/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1842 - cce: 0.0117 - acc: 0.9967 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.5182 - val_acc: 0.9863\n",
      "Epoch 136/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1826 - cce: 0.0104 - acc: 0.9968 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6601 - val_acc: 0.9856\n",
      "Epoch 137/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1808 - cce: 0.0093 - acc: 0.9969 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7803 - val_acc: 0.9858\n",
      "Epoch 138/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1806 - cce: 0.0066 - acc: 0.9968 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7039 - val_acc: 0.9864\n",
      "Epoch 139/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1851 - cce: 0.0117 - acc: 0.9969 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6075 - val_acc: 0.9874\n",
      "Epoch 140/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1816 - cce: 0.0168 - acc: 0.9968 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7477 - val_acc: 0.9878\n",
      "Epoch 141/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1757 - cce: 0.0054 - acc: 0.9973 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6328 - val_acc: 0.9870\n",
      "Epoch 142/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1746 - cce: 0.0036 - acc: 0.9972 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6274 - val_acc: 0.9875\n",
      "Epoch 143/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1775 - cce: 0.0049 - acc: 0.9972 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6824 - val_acc: 0.9879\n",
      "Epoch 144/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1767 - cce: 0.0073 - acc: 0.9973 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.8077 - val_acc: 0.9876\n",
      "Epoch 145/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1767 - cce: 0.0069 - acc: 0.9972 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6898 - val_acc: 0.9883\n",
      "Epoch 146/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1818 - cce: 0.0165 - acc: 0.9976 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7754 - val_acc: 0.9879\n",
      "Epoch 147/150\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.1796 - cce: 0.0096 - acc: 0.9972 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.8404 - val_acc: 0.9875\n",
      "Epoch 148/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1769 - cce: 0.0069 - acc: 0.9973 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.7719 - val_acc: 0.9880\n",
      "Epoch 149/150\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1741 - cce: 0.0051 - acc: 0.9974 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6525 - val_acc: 0.9870\n",
      "Epoch 150/150\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1754 - cce: 0.0098 - acc: 0.9974 - rank_1: 600.0000 - rank_2: 300.0000 - val_cce: 1.6393 - val_acc: 0.9880\n",
      "2 was too complex and was recomposed. It had rank <tf.Variable 'first/Variable:0' shape=() dtype=int32, numpy=600>\n",
      "4 was too complex and was recomposed. It had rank <tf.Variable 'second/Variable:0' shape=() dtype=int32, numpy=300>\n",
      "Model: \"custom_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " recomposed_dense (Recompos  (None, 600)               471000    \n",
      " edDense)                                                        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 600)               0         \n",
      "                                                                 \n",
      " recomposed_dense_1 (Recomp  (None, 300)               180300    \n",
      " osedDense)                                                      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " recomposed_dense_2 (Recomp  (None, 10)                3010      \n",
      " osedDense)                                                      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654316 (2.50 MB)\n",
      "Trainable params: 654310 (2.50 MB)\n",
      "Non-trainable params: 6 (24.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"custom_model_1/activation_3/Softmax:0\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(1000, 10), dtype=float32)\n",
      "Tensor(\"custom_model_1/activation_3/Softmax:0\", shape=(1000, 10), dtype=float32)\n",
      "60/60 [==============================] - 2s 14ms/step - loss: 0.0020 - cce: 0.0018 - acc: 0.9977 - val_cce: 1.6315 - val_acc: 0.9881\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0012 - cce: 0.0019 - acc: 0.9978 - val_cce: 1.6261 - val_acc: 0.9880\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 7.2825e-04 - cce: 0.0013 - acc: 0.9977 - val_cce: 1.6189 - val_acc: 0.9881\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 3.4291e-04 - cce: 8.3756e-04 - acc: 0.9977 - val_cce: 1.6143 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 7.5081e-05 - cce: 8.9156e-05 - acc: 0.9978 - val_cce: 1.6109 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 1.9417e-07 - cce: 4.5871e-08 - acc: 0.9978 - val_cce: 1.6104 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 1.4700e-08 - cce: 8.6833e-09 - acc: 0.9978 - val_cce: 1.6104 - val_acc: 0.9881\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 1.0818e-08 - cce: 1.1045e-08 - acc: 0.9978 - val_cce: 1.6104 - val_acc: 0.9882\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 9.2147e-09 - cce: 1.0041e-08 - acc: 0.9978 - val_cce: 1.6104 - val_acc: 0.9882\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 8.1418e-09 - cce: 7.8177e-09 - acc: 0.9978 - val_cce: 1.6105 - val_acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f2ee817d2a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import CustomModel\n",
    "import CustomMetrics\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x = x_train\n",
    "y = y_train\n",
    "\n",
    "y = keras.utils.to_categorical(y, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "# Construct an instance of CustomModel\n",
    "inputs = keras.Input(shape=(np.shape(x)[-2], np.shape(x)[-1]))\n",
    "flattened = keras.layers.Flatten()(inputs)\n",
    "outputs = SVDDense(\n",
    "    units = 600,\n",
    "    mu_comp = 0,\n",
    "    prune_threshold = 0.5,\n",
    "    pruning_batch_size = 15,\n",
    "    mu_ort = 2,\n",
    "    mu_sing = 1,\n",
    "    name = \"first\"\n",
    ")(flattened)\n",
    "outputs = keras.layers.Activation('relu')(outputs)\n",
    "outputs = SVDDense(\n",
    "    units = 300,\n",
    "    mu_comp = 0,\n",
    "    prune_threshold = 0.2,\n",
    "    pruning_batch_size = 6,\n",
    "    mu_ort = 2,\n",
    "    mu_sing = 1,\n",
    "    name = \"second\"\n",
    ")(outputs)\n",
    "outputs = keras.layers.Activation('relu')(outputs)\n",
    "outputs = keras.layers.Dense(\n",
    "    units = 10,\n",
    ")(outputs)\n",
    "outputs = keras.layers.Activation('softmax')(outputs)\n",
    "model = CustomMetrics.CustomModel(inputs, outputs)\n",
    "\n",
    "# We don't pass a loss or metrics here.\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=6e-3, momentum=0.4, clipnorm=4.0))\n",
    "\n",
    "# Just use `fit` as usual -- you can use callbacks, etc.\n",
    "model.summary()\n",
    "firstFit = model.fit(x, y, epochs=150, batch_size=1000, validation_data=(x_test, y_test))\n",
    "\n",
    "#Recompile the model to only use the pruned version.\n",
    "outputs = flattened\n",
    "input_size = np.shape(x)[-1]\n",
    "for layerIndex in range(2, len(model.layers)-2):\n",
    "    layer = model.layers[layerIndex]\n",
    "\n",
    "    if isinstance(layer, SVDDense):  \n",
    "        if (layer.input_shape[-1] * layer.units) > (int(layer.rank) * (layer.input_shape[-1] + layer.units)):\n",
    "            weights = layer.get_weights()\n",
    "            outputs = DecomposedDense(\n",
    "                units = layer.units,\n",
    "                u_sigma = np.matmul(weights[0][:, :int(layer.rank)], np.diag(weights[1][:int(layer.rank)])),\n",
    "                vt = weights[2][:int(layer.rank)],\n",
    "                b = weights[3]\n",
    "            )(outputs)\n",
    "            print('Kept decomposed layer', layerIndex, 'with rank: ', layer.rank)\n",
    "            print(layer.sigma[:layer.rank])\n",
    "        else:\n",
    "            weights = layer.get_weights()\n",
    "            outputs = RecomposedDense(\n",
    "                units = layer.units,\n",
    "                weights = np.matmul(np.matmul(weights[0][:, :int(layer.rank)], np.diag(weights[1][:int(layer.rank)])), weights[2][:int(layer.rank)]),\n",
    "                b = weights[3]\n",
    "            )(outputs)\n",
    "            print(layerIndex, 'was too complex and was recomposed. It had rank', layer.rank)\n",
    "    else: #if isinstance(layer, keras.activations) :\n",
    "        new_layer = layer.__class__.from_config(layer.get_config())\n",
    "        outputs = new_layer(outputs)\n",
    "        \n",
    "layer = model.layers[len(model.layers)-2]\n",
    "weights = layer.get_weights()\n",
    "outputs = RecomposedDense(\n",
    "    units = layer.units,\n",
    "    weights = weights[0],\n",
    "    b = weights[1]\n",
    "    )(outputs)\n",
    "outputs = keras.layers.Activation('softmax')(outputs)\n",
    "\n",
    "\n",
    "newModel = CustomModel.CustomModel(inputs, outputs)\n",
    "newModel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=8e-4, momentum=0.6, clipnorm=2.0))\n",
    "newModel.summary()\n",
    "newModel.fit(x, y, epochs=10, batch_size=1000, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce4656e-7673-465d-b917-3ab17caa9b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f09e3ca4160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7h0lEQVR4nO3dd3xUVdrA8d+k9wAJaSRA6B0h1NBFQRSEF1fAQlFQsYK4FkQUXVnEFUVUcK2osICKKCoKQRRBQIqELjWQEBJCQsikl5nz/nGYSYYUkhBSn+9+5jMz555755yBdR6eU65BKaUQQgghhKjG7Kq6AUIIIYQQVyMBixBCCCGqPQlYhBBCCFHtScAihBBCiGpPAhYhhBBCVHsSsAghhBCi2pOARQghhBDVngQsQgghhKj2HKq6ARXFbDZz7tw5PD09MRgMVd0cIYQQQpSCUorU1FSCgoKwsys+j1JrApZz584REhJS1c0QQgghRDnExMQQHBxc7PFaE7B4enoCusNeXl5V3BohhBBClIbRaCQkJMT6O16cWhOwWIaBvLy8JGARQgghapirTeeQSbdCCCGEqPYkYBFCCCFEtScBixBCCCGqPQlYhBBCCFHtScAihBBCiGqvzAHL77//zogRIwgKCsJgMPDtt99e9ZzNmzcTFhaGi4sLzZo14/333y9UZ/Xq1bRr1w5nZ2fatWvHmjVryto0IYQQQtRSZQ5Y0tPT6dy5M++++26p6kdFRXHrrbfSr18/9u7dy/PPP88TTzzB6tWrrXW2b9/O2LFjGT9+PPv27WP8+PGMGTOGP//8s6zNE0IIIUQtZFBKqXKfbDCwZs0aRo0aVWydZ599lrVr13LkyBFr2dSpU9m3bx/bt28HYOzYsRiNRn766SdrnVtuuYX69euzYsWKUrXFaDTi7e1NSkqK7MMihBBC1BCl/f2+7nNYtm/fzpAhQ2zKhg4dyu7du8nNzS2xzrZt24q9bnZ2Nkaj0eYhhBBCiNrpugcs8fHx+Pv725T5+/uTl5dHYmJiiXXi4+OLve68efPw9va2PuQ+QkIIIUTtVSmrhK7cbtcyClWwvKg6JW3TO3PmTFJSUqyPmJiYCmyxEEIIIaqT634voYCAgEKZkoSEBBwcHPDx8SmxzpVZl4KcnZ1xdnau+AYLIYQQotq57gFL7969+f77723KNmzYQLdu3XB0dLTWiYiI4Mknn7SpEx4efr2bJ4QQQtQambmZnL50muSsZHJNueSac8kz51lfuzu606x+M5rWa4qDnQNJmUnEGmM5azxLbKp+zszNpIFrA3zcfPBx9bG+buDaAH93fxztHaukb2UOWNLS0jhx4oT1fVRUFJGRkTRo0IDGjRszc+ZMYmNj+fzzzwG9Iujdd99lxowZPPDAA2zfvp2PP/7YZvXPtGnT6N+/P/Pnz2fkyJF89913bNy4ka1bt1ZAF4UQQohrk5CewKGEQzT2bkyz+s2sUxYSMxLZfW43hy8c5u/EvzmWdIy0nDRMyoRSii6BXfhH239wU7ObcHYo3ahAjimHpZFLMWYb6R3cm7CgMMzKzIHzB9h/fj8p2SnYGeywN9iTmJFI1KUo/UiOIi4trlSfYWeww9HOkWxTdpm+h00TNjEodFCZzqkoZV7W/NtvvzFoUOHGTpw4kaVLlzJp0iROnz7Nb7/9Zj22efNmnnzySQ4dOkRQUBDPPvssU6dOtTn/66+/5oUXXuDUqVM0b96cuXPnMnr06FK3S5Y1CyFE9aSU4qO/PmJj1EYaujUkyDOI1j6tGdF6BE72TiWeazKbiDgVwf7z++nZqCe9Q3oXOseszBy+cJgjF47QokEL2jVsh7ODM+fTzrP97HaikqO4teWttPZtXej66Tnp/O/A//jh+A94OXvR2KsxgZ6BGLONJKQncNZ4lj1xezh96bT1nAauDejs35kzKWc4lXyqVN+Bl7MXfu5+ZORmkJmbiZO9Ex5OHng6ezKo6SCe7fMs/h7+xBpjGfP1GLbF5K+SdbRzxKRMmJW5VJ/l6eRJQ/eGONo54mjviKOdI072TjjaO3Ip6xInL54kMy/TWr+hW0OCvYJp5NWIYM9g3BzduJh1kaSMJC5mXiQp8/JzRhJ/PfQXnfw7laodpVXa3+9r2oelOpGARQghKpdSiuMXj7Pj7A5yTbnc0uIWGnk1sqlzKesS9393P2v+Lrx7ebBXMP/s/U+mdJ2Cu5O79ZqxqbEcSzrGpqhNfLbvM84az1rP8XDyIDwkHG9nb5wdnEnPSWdL9BYSMxKtdRzsHPBz9+Nc6jmbzxveajgPd3sYO4MdZ41n2Ru3l2UHlmHMLt22GE3rNeVc6jlyTDk25a19WtPJvxNtfNvQ2qc19VzqYW9nT64pl4hTEaw+srpQW67k5ujGfTfcx5eHvuRCxgW8nb0Z0HQAf579k/Pp5wHwc/fjhoAb8Hf3x6zMmJQJb2dvQuuF0qx+M0LrhxJaL5QGrg1KXLSilCIuLY7svGyCPINKnfkpasFMRZCARQghxFUlZiTy/dHv+eH4DzjaOTK+03iGthiKg13hGQMpWSnsjN3JjrM72BG7gx1nd3Ax86JNnR6NejCo6SA8nTxxdnBm8a7FRF2KwtHOkad6P4W9nT2xqbGsP7HeOnzhYOeAq4MrDnYOZOVl2fzrH3RGo2/jvuw4u4OE9IQi++Hm6Ea7hu04efEkyVnJABgw0N6vPf7u/myK2oSi6J+7Fg1acN8N92FvsCfGGENcWhzezt74u/vj5+5HJ/9OdAvqhreLN9l52ew/v5/95/fT2Lsx3YK6Ud+1fonfsVmZiYyPJDM3E1dHV1wdXMkx5ZCWk8a51HO8sf0NdsbutNbv7N+Z1WNW07xBc5RSxBhjcLJ3IsAjoMTPqakkYBFCiFpCKcXuc7vJM+fRJbALLg4uAGTkZnD4wmGc7Z1p0aAFro6ugB5GSUhP4NCFQ/wV9xeR8ZE42jvSya8Tnfw7kZqTyvaY7Ww7u40dZ3cUGmoI8gxiaPOheDt74+HkQVxaHDvO7uDwhcOFfvSd7Z3pFtQNkzKx4+yOItvftF5TvrrzK7oFdbOWZeVl8fm+z3n9j9c5mXzSpr6DnQPN6jejfcP23NXhLm5vfTvODs6YlZn95/ez59weMvMyycrLws5gR89GPeneqDtO9k4opThrPEt0SjTt/dpTz6UeAMeTjvP2n2+z9uha6rnUI9grmCbeTRjddjSDmw3GzlB19wJWSvHDsR94Y/sbdGjYgTeGvGH9s6wLJGARQohKkJmbyaaoTWyJ3oKDnQNezl7Ud6nPba1uI8gzqFTXMGYbOXLhCIcvHCbqUhThIeEMbT4Ug8FAVl4Wj/74KJ9EfgLo+QydAzqTlpPGsaRjNsFGiFcIZmUmPi0ekzKVug9dArowsvVIUrJT+Hzf5yRlJhVbN7ReKL1DetOrUS96Bfeic0Bn65ySuNQ41h5dy8GEg2TmZZKZl0mQRxDP93u+2CyEyWzirPEsueZcTGYTDnYONPZuXGUrUUTlk4BFCCGuo01Rm1i4YyEbT20sNIQB4OrgyhM9n+DZPs8SlxbHigMrWHdiHQ52Dvi7++Pj5sNZ41kOXzhc5PyGgU0H8nT407yy+RX+jP0TO4MdPq4+XMi4YFOvoVtDcs25XMq6ZFNuZ7AjtF4oXQO70iWgC7nmXOtQhouDC+Eh4YSHhDOgyQCa1GtiPS87L5sfj//I34l/k5qdSmpOKl7OXvRs1JNewb3w9yh+fywhykMCFiGEuOxc6jl2nN1BJ/9ONK/f/JomDf4R/Qezf53Nr6d/tZaFeIVwS4tbcHFwwZht5NCFQ+w+txsAJ3unQpM0ixLkGURb37b4ufvxzZFvbJab1nepz6p/rOKmZjdx+tJpdp/bjYeTB10CuxDgEYBSiqTMJE5cPIGDnQNBnkH4u/tjb2df7n4KUVlK+/t93TeOE0KIkpw1nuX+7+5nZ+xOOvl3okejHoSHhDOk+RA8nDxs6pqVmcSMRGKNsWTmZdLapzU+bj7FXjs5M5n5f8zn7T/fJisvC9ArUyyrTJzsnXB1cMXXzRc/dz9cHV35O/Fv9p/fz7nUc4xuO5qHuz2Mp7MnJy6e4OmIp/n2728BHYg82PVBHgx7kA5+HWyCIMuchOc3Pc/BhIM42jlyS4tbGNt+LB5OHpxPP09iRiIBHgG0a9iONr5trHMtAKJTopn962y+2PcFHfw68O24b2lWvxmAXglSP9SmnwaDAV83X3zdfK/lj0KIak0yLEKIKrPh5Abu+eYemyWpFi4OLtzS4ha6BnTlSOIR9p/fz/GLxwtlK/zc/Wjt05qG7g3xcfXB3dGdi1kXScxIZFvMNutQSfP6zYlOiSbXnFumNtZzqceQ5kNYc2QNueZc7A323HfDfcweMJvG3o1LPNdkNrH//H6a1GtCA9cGZfpc0JuVNXBtUOSKHSFqCxkSEkJUWyaziZc3v8yrv7+KQtEloAtvDX2L05dO82fsn6w/ub7EDbn83f1xsncixnj1m5528OvAa4Nf49aWt5KZl8m2mG1ExkeSlZdFjimHjNwMEjMSSUhPIDUnlVYNWtHJvxPODs4s3LGQo0lHrdca1mIYbwx5g3YN21XI9yDE9ZaQANnZEBJiW56XB4cPw65dsHs31K8PzzwD9erl14mNhQsX4IYbrm8bJWARQlwXRxOP4mDnQPMGzct1fkJ6Anevvptfon4B4KGwh1h4y0LrUl3QQyr7zu9j9eHVnEk5Q7uG7ejo15F2DdvRyKuRdVVKWk4aRy4c4WTySZIykkjKTCI9J50Grg3wdfMlxDuEwaGDyz2Xw2Q2sebvNaw9upZ7Ot7D0BZDy3UdUblycuDoUejQASpqj7PTp+HVV2HYMLjjjsLHldI//N99B35+0K8fdOoE9hU4jUgp+PxzyM2F4cMh4PK2LPHxsH49pKZCo0b6sX8//O9/8Ntv+rymTWHgQPDy0kFKZCRkXjFXPDgYPv0UuneHf/8b3n5bBzujR8OCBfoa10Opf79VLZGSkqIAlZKSUtVNEaJWuphxUU39fqoyzDEoh1cc1OxNs1V2Xnapzs0z5amjiUfVsn3LVOAbgYo5KLe5buqLfV9c51aLqvTkk0q1aaPUlClKrVihVEyMUnl513bNn39W6t57lfrxR6XM5qKPt2qlFCg1ZoxSWVnX9nlKKRUXp1Tz5vqaoNTddyt18aL+/AMHlJo/X6n27fOPWx5eXkr985/la0NCglKZmfnvzWalpk3Lv7bBoFSvXkqFhRX+3Csf9vZFl3t5KTVokFJPPaVUixb55d7eheu6uCg1Z45SGRnX/n1eqbS/35JhEUJYXUi/QNSlKGJSYjhrPEtGbgagN/lasntJoSW1Hfw6MKHTBPbG77XZ2KxLQBdcHVw5kHCAAwkHOHzhsHXSK0Bb37Z8PeZrGVqpxb7+Gu68s3C5nZ3ODLRsCZMmwdix4HrFHmlmsx6e+Ppr+Ne/4N57daZk5Ur92nR5i5lOneDxx/X5KSmwYYPOcBR0442wZg04OcEPP8DPP8PFi7p+ZqYeKmnRQmclTp+GQ4cgJgaGDoUZM/S1Bw6Efft05iQpSX9+QIBuU1yBew26uMCIETrTsW0bGC/v+N+1q257y5bFf1/Z2bB1K/z0k34cPgw+PvDCCzB1Kvzzn/Dee7pu5866PQV166b7EhurH76++ru96y79+o8/YPNmyMqCsDBdv2VL/ecBkJ6uv/PFi/X7Nm3gP/+BJk3giSd0pgZg6VKYOLH4fpSHDAkJIYqUZ87j8IXDnEo+xVnjWWJSYjh44SCR8ZFXvd9Ju4btWHzrYhLSE3hk3SNFTpYtjquDK+392jOwyUBeGvhSoRVAomZKS9NBgIOD/rG2t9fzJtq3h8REuO8+PT/il1/gwAEdjBRUvz7cf7/+sfTz0/+ef/RRWLIkv85dd0GfPjo4UQrCw/UPdnp64fbY2+sf2H79YMIE3b5mzXSgkZJStr45O+sg4MQJ8PfXAUVSkr7usWO6jqsr9O+vh4nGjAFvb11uMsHatfDAA/ocDw/o0UMHE3FxOhjp2FEHBn//rb+fovoD+popKTpA+ugj/X2dOwfr1oGjow6uAipo1/4tW3TAdued+tqgv/OvvtJDTKtXV+wwF0jAUtXNEaLKHDh/gMbejfF28baWmcwm3tz+JmuPrbVua16cYK9gQrxCaOTVCC8nL9Tl/4UFhvFQ2EPWHUgvpF/g5c0vE5saS1hgGD0a9cDRzpG98XvZG7+XHFMOHRp2oINfBzr6dyS0XqjsC1JNmM16HsO6dToLEBKiH+7ukJGhMw/du+sf04LmzdP/Um/QQP+r/dQpHaxkX94ypn9/+OwzePppnR3p2FF/jvPle+uZTDqYiY3VP9Dvv6+zGqB/0J95Bs6f15kEg0EHKqtW5WdUAB58UAczly7peuvX66DBy0sHFY8+qoMlgD179JyTC5cTg40b66xDs2a6vrMzREfD8eNw9qw+3r69DhDee09nSUC/37xZZzZAf0dr10LDhjqQcsmfflXI2bNwzz3w++9X/3MJCIBbbtFtHjRIZ4teekkHJwaDnl9S0dmN6kACFiHqoN9O/8agzwbR2b8zOx/YaZ2cuujPRUz7eZq1npezF2182xDiFUKwVzAtG7SkS2AXOvp1xNPZs6qaLyrI8eP6x79VK3jttfyJpyYTzJyp0/oXLpR4CeztdTAweLB+/+mn+l/2RWnRQmcN0tP1j3dWlj5/5049HFIck0kPf8yZo4MLC4MBPvlEDxnt2AF33w1RUTB9Orz5Ztkm0kZFwRdfwIABOutiV8pbBimlsw0rV+p+d+t29XOKYzLp4CMjQw89BQbqibIHD8KRI7ps2DAdEF3ZvowM3f5mzeDmm8vfhupMAhYhaiGlVIm7tN72v9tYd3wdAK8OepVZ/WdxPu08rd5thTHbyDPhzzDphkm09m1dpTd7u9LRozoNfdNNVd2S8tm+Xa+qmDbNtg/x8fDiizr937WrnjvQrFn5PuPoUf0vcO/8xBmZmTqjYTbrf5mHhuohg+nT9Q8dwKJFeigFYPZsvdIF9HVuuUVnVmJi9CMrC9zcdPbi4EE9XPPnn7q8Rw/9/MADOkBJSgJPT7j9dp1JOXVK/+v/jz/yP+uVV0rXN7MZvvwSnn9eZzz++1+YPDn/eEaGvn779hW36kdUH7JKSIhaZvPpzcpnvo/6v5X/py6kXyh0/O8LfyvmYH04/8tZHU08qiasmaCYgwr7b5jKM13jEo3rIDNTqYAAvRLhjz+uz2ekpir1yy9Fryq5VhERSrm55a+6OHVKl+fkKNWnT+HVFnfeWfqVFmazUuvXKzVwoD63fn2l3n5bX3vbtvzVMJaHv3/+65Yt9bOjo1I7dyq1dm3+scWL9TWKk5mpVM+eum7r1voBSg0dqpTJVPx5eXlKvfuuUjNnKpVdugVkNnJzlbpQ+K+2qOVK+/stAYsQ1VCuKdfmfWJ6omq0oJE1GGm0oJH6Leo3mzoP//CwYg5qxP9GqKFfDFXMQbV5t41iDsowx6D+PPtnZXah1D78MP+HdOLEir9+To5S4eH6+gsW2B47e1aXxcaW79rffaeUk1P+sk9QqkcP/Zn//Gd+EDNlilLduuUvL+3TR6nExOKvm5en1FdfFb9kNSREKTs7/TooSKkBA5RycNDvnZyUeuMNfY3Ro3VZ48b5S1Uff7x0fYuLUyo4OP8zGzWSYEJcHxKwCFFDbTmzRbm86qLu/PJOdTHjojKbzWrUylGKOagWi1qo1u+0VsxB2b1sp/61+V/KZDappIwk5TbXTTEHtenUJhWVHGV9zxzUA2sfqOpuFclkUqpt2/wfRTc3pS5dKrpudrYOMMrq6adt9504fz7/ep065e878eGHJWdgzGYdoIwcqYOS5s3zg4b/+z+ljh1Tql49/f6mm/I/c/Xq/Gv89lt+ndat9T4lQ4Yo1bSpUt27K3X//Uq9/HJ+RsPynUybplRUlFL//a9Sfn75xyZM0PuBKKVUSorOxlgyPErp77JZs/z6ffqULfOxZ49Srq46GNq6tfTnCVEWErAIUUPdvfpua6DR5K0m6smfn1TMQTm+4qj2nNujUrNT1aRvJ1nrjF41Ws3eNFsxB9VpSSdlvvyru2DbAsUcVIP5DYocQqoOfvhB/5B6euYPYbz/fuF6KSlKdemijz/zTMnDGUVd35KJAKUeuBy7zZpVOHMxaFDR2ZbNm5Xq3bvobMfEiXooQykdnBQ89uSTha918KDOkFxts6969ZSaPbtwViMlRak339TBSWns2aOUu7vOkJQnkxQdrdTRo2U/T4jSko3jhKjGMnMz+WL/F/xw7Aee7fMsfRr3sZb7veFHWk4afu5+JKQnWM954+Y3eCr8Kev7j//6mId/fNjmZn6f3P4J93W5D9BLmT/66yO6Bnale6PuldSzsrnxRvj1V3jqKQgK0s/duumlsBaWbcg3bMgvCw/XqzeuvD9KQSdOQK9eenLo44/rPTL69dOTNv/7X70Zl9msl82ePas36MrMhNat9RJWf3+9uuPJJ+Gdd/Q1XV31tcLD9UTaoKDCk2gffVRvvtWrl76Ok1PhtsXG6k25DAY9kbR1a72c98ABvb9Ht256+a5nBS3YunBBT6Z1d6+Y6wlRkWTSrRDV0JlLZ9RLv76kGr7e0Joh6bC4gzUrsubIGsUcVPCbwepS5iU17utxijmoYcuGKZO58GzHbdHbrFvdN3y9ocrMzSxUp6pt3KjU8uWFh1v27MnfNvzMGb0VuaOjLouM1HXMZj1MYhkaee01PawDSjVooNTXX9teMypKD6l065afqQgLy98afexY2yzGXXfln3vsWH7mo2NHnVkYOTK/7tSpSp07d/X+mky6z+np5f3GhKhbZEhIiGoiJiVGvb/rfdXvk342q3gav9VYuc91V8xBrT+h8/uW4aAnf9ZjCWazWR1NPFpoEm5BscZYNe2naWrTqU3X1M7z5/XkzfvuK3klSFls25Y/z+PFF/PLTSY97wP0fVks7rxTlz32mFJ//qmHW0Bf4/vvdZ0TJ2wno44fr9S+fXqoxzLx1PLo29d2Tsfp0/mTYwMClEpKsm3v8eNKBQbmr64BpZydlfryy4r5PoQQhUnAIkQVMJlN6ljiMfW//f9Tj6973LpKx/IwzDGoAZ8OUCsPrFS5plw17adpijmooV8MVRk5Gcrj3x6KOajtMdsrtd05OUr165f/Q//mm7bHDx/W2YuyMBptJ3yCUu+9p8tHjcov27Mn/5z164uez7F4se21s7OVev75/GCo4GPwYKU+/livcinKW2/p7Exxc0AOH1aqYcP8ZcRbtpSt30KIspE5LEJUslUHV/HIuke4mHnRptzOYEf3oO7c0fYOxnUYR4h3/sSLU8mnaPlOS8zKzL8G/YvZv84mxCuEM9PPlLhBXEV77DG9FbmDA+Tl6S3L9+zR8ys++EDP93B3h7/+KvkGbgVNnqx3K7Vsh26ZsxEaqjcBc3KCDz/U92WxMJv17qwnT+o5F6NG6V1GLbutXmnbNn3+yZO6zssv663Sr9Xff8PHH8OUKXp+iRDi+pGdboWoRBEnI7j1f7eSZ87DxcGFzv6d6RbUjUFNB3Fj6I3Ud61f7Ln/+PIfrD6yGgMGFIoZvWawYOiCSmv7J5/k7yr63Xd6Quq6ddClC4werXcstejWTe9kWtREUgul9K6l48bpAOW33/Rk14I3tAsI0HfQ7dWr8PmnT+vJp4MG6fvLXE1Wlp4026JFaXsshKhOJGAR4hqlZqeyNXorg0IH4eJQ/N3NIuMj6f9pf1JzUrm7490sHbnUeoPA0tges53wT8Lz30/eTq/gIn7JS8ny/+iCCZqUFJ0t6NlT36be4sABHYTk5OjsxIsv6nvCdOgAFwskih5/HJYtg+RkeO45fRO8o0f11utnzujVOo0b65Uumzbpbd4hvy7oFTdPP60Dknfe0fdPEUIIWSUkxDXIzstWPT/saZ0c++neT4vc1v7MpTPWVTqDlg5SWblZ5fq8Xh/1sn6WuYTdy6KjS96D5OBBPT9j3Di906nFhAn5czy+/VaX5eTk721y2222E22//DK//ltv6bKvv9bvDQZ9fcuurUU9nJz0CpzybM8uhKhbZA6LENfgyZ+fZOGfC23K2jdsz9q71tKsfv7GG5abDXb068iW+7bg7eJdrs/beGojty6/lddueo0ZvWcUWSciAoYO1cM0X39d+LhS+o60W7bo95bsxpo1+hyL+vVh3z49R+Pll6FBAzh0SA/TFPTtt1CvHgwcmF/2wAP65noWI0booZ+4OH3TOnd3PZTTp4+egyKEEFcjQ0JClNOaI2sY/aX+hV/1j1WcuXSGeVvnkZyVzMCmA9k0YRMGg4Hfz/zOgKUDcLBz4PAjh2npU8rZqMUwK3OJd1C+6Sb45Rf9+ocf4LbbbI8vWwbjx4Ojo95sDeCtt/RdhC9cgBkzdDCza5e+u+6RI3qC7YoVOugojfR0GDkSsrP1cNCgQeXoqBBCFCABixDlcCr5FF3/25WU7BT+2fuf/GfIfwCISo6i/eL2ZOZlsuz/lnF3x7vp+2lftsVs4+FuD7P4tsXX9Llbt8Ltt8PcufDww4WPHz6sV+xYNG8OBw+Cy+WpNSkp+bul/vvfkJqaP3cEdICya5feYbVLFzAadfk//qEnyFbigiQhhLBR2t/v4v85J0QdNGP9DFKyU+gd3Jt/D/63tTy0figv9H9B19kwg2X7l7EtZhuuDq7M7j+7uMuV2quv6gmtr7yisx5Xevdd/TxkCAQG6mW8b76Zf/yll3Sw0qqVzqS8+qrOhIDOuHzxhV6q3KyZXqYM4Oent5CXYEUIURNIhkWIyy6kXyDozSDyzHkcfPgg7f3a2xzPMeXQ+f3O/J34t3UJ8sy+M20Cm/I4dUovybX8P/G773S2xSIlRa+oSU/XK3BiY/XQj5sbzJ+v57b88IPew2TDBrj5Zn1eair86196SfGIEbafuXWrvmZo6DU1XQghrplkWIQooy8PfUmeOY+wwLBCwQqAk70Ti2/VQz8KRX2X+jzT55lr/twPP9TBiiXT8fHHtsc//VQHK+3b6wmw99yjJ7VmZOjlxmvX6mDlgQfygxXQN857/fXCwQpA374SrAghahYJWIS4bNmBZQDc2+neYusMCh3ExM4TAXhxwIvUc6lXps/Iy9MZkbQ0/T4nJz9AefVV/fzjj3rVDehA5L339OvHHtNBjcGgN2Br3BjCwvQwUmSk3vBNCCFqKxkSEgI4cfEELd9piZ3BjtgZsQR4BBRbN8+cx774fXQN7Frm7fMnTYLPPoNOnWD9eti8Wa/QCQrSG6oNHKi3m583Ty9LXrQIpk0Db2+9m2tpdn4VQoiapLS/3w6V2CYhqq3l+5cDcHOzm0sMVgAc7BwICwor82d8/rkOVgD279fDMvXq6fdTpujJsVOm6IDlo490JuW55/Txf/5TghUhRN0mQ0KizjiYcJCFOxaSmJFoU66UKtVw0LU4ehQeeUS/fuQRPX/k5El9g0E7Ox2oANx5pw5MTp7MD1ZmzoRZs65Ls4QQosaQgEXUGXevvpsn1z9Jy3da8u7Od8kz6/XDO2N3cuLiCdwc3bi91SgSEir2czMzYcwYPXH2xhv1MM/Wrfn7qgwfru/FAzpYueuu/HNfe03vqyJLj4UQdZ3MYRF1QnRKNE0WNrEpC/EKwcXBhYT0BFKyU7i30700+O0LFi3S2Y25c3X241rExuo5Klu3QsOGekv8wEB97OJFPUx05522NwI8dUpnXCZM0HNehBCiNpM5LEIU8POJnwHo2agnEzpP4IVNLxBjjLEetzPYMaXzVEZfHpp57TW9u+yyZXp5cFFMJr3k+IsvIClJ7x6bkwP9+8P//Z/OlkyerLfF9/SEVavygxXQ9/CZPr3wdZs10/utCCGEyCcBi6gTfjrxEwC3tbyNR7o/wl0d7mLXuV24Orji5exFoGcgf+/x4+JFfQO/vDy9v0mfPvDrr+DjY3u99ev1RNiDBwt/1ldf6YdF5876ZoUtWlzHDgohRC0nc1hErZdjymHjqY0A3NryVgDqu9ZnSPMh9GvSj84BnfFz9+P773X9//s/+O038PeHAwfyt7K3WLIEbrlFByv16+vN2TZuhJ079dDPzJnQpo2uO3kybN8uwYoQQlwrybCIWu+P6D9Iy0nDz92PLoFdiq1nCVhuvx169YIXXtA7yW7apIMQiw8/1M/33QdvvKGHdgrq0yf/BoTFDScJIYQoG8mwiFrPMhx0S4tbsDMU/Vf+2DG99NjREYYO1WU33qift26F7Gz9+sIF2LtXv543r3CwUpAEK0IIUXEkYBG1niVgGdZiWLF1LNmVgQPBMkm9bVs9LJSVBX/+qct++UU/d+qkjwkhhKgcErCIWi0mJYaDCQexM9gxpPmQYuutXaufC94o0GCAQYP0a8uqnYgI/VzwJoNCCCGuv3IFLIsXLyY0NBQXFxfCwsLYsmVLifXfe+892rZti6urK61bt+bzzz+3Ob506VIMBkOhR1ZWVnmaJ4RVweXMDVyLHr9JSoI//tCvr7yzsWVYaNMmfUdlCViEEKJqlHnS7apVq5g+fTqLFy+mT58+/Pe//2XYsGEcPnyYxo0bF6q/ZMkSZs6cyYcffkj37t3ZuXMnDzzwAPXr12dEgV8HLy8vjh49anOui4tLObokRL51J9YBJQ8H/fST3lOlY0do2tT2mCXDsmOHviNyTAw4OUG/ftenvUIIIYpW5gzLm2++yeTJk5kyZQpt27Zl4cKFhISEsGTJkiLrf/HFFzz00EOMHTuWZs2aMW7cOCZPnsz8+fNt6hkMBgICAmweQlyL82nn+fHYjwDc3vr2Yut9+61+vr2IKs2b623zc3Nhzhxd1rcvuLlVbFuFEEKUrEwBS05ODnv27GHIENu5AEOGDGHbtm1FnpOdnV0oU+Lq6srOnTvJzc21lqWlpdGkSROCg4MZPnw4ey1LMYqRnZ2N0Wi0eQhR0Ed/fUSuOZdewb3oHNC5yDrx8fDdd/r1nXcWPm4w5A8LWea5yHCQEEJUvjIFLImJiZhMJvyvWB7h7+9PfHx8kecMHTqUjz76iD179qCUYvfu3XzyySfk5uaSmKjvmtumTRuWLl3K2rVrWbFiBS4uLvTp04fjx48X25Z58+bh7e1tfYRY7h4nBJBnzuO/e/4LwCPdHim23kcf6V1tw8P1jrRFsQwLWUjAIoQQla9ck24NV9w6VilVqMxi9uzZDBs2jF69euHo6MjIkSOZdPmObvb29gD06tWLe++9l86dO9OvXz++/PJLWrVqxTvvvFNsG2bOnElKSor1ERMTU2xdUff8cOwHYowx+Lr5cmd7nTrJzIQzZ/Lr5OXBf3VMwyPFxzQ2AYuPD3Qpfu85IYQQ10mZAhZfX1/s7e0LZVMSEhIKZV0sXF1d+eSTT8jIyOD06dNER0fTtGlTPD098fX1LbpRdnZ07969xAyLs7MzXl5eNg8hLBbvWgzA5C6TcXFwQSk9RyU0FD7+WNf5/ns4exZ8feEf/yj+Wo0b52+tP3jwtd/BWQghRNmV6T+9Tk5OhIWFEWFZ23lZREQE4eHhJZ7r6OhIcHAw9vb2rFy5kuHDh2NXzH/5lVJERkYSWPDWtkKU0rGkY0ScisCAgYfCHgL0zQc3btRLkx98UAcri3VMw5Qp4Oxc8jXHjdPPd999HRsuhBCiWGVe1jxjxgzGjx9Pt27d6N27Nx988AHR0dFMnToV0EM1sbGx1r1Wjh07xs6dO+nZsyfJycm8+eabHDx4kM8++8x6zZdffplevXrRsmVLjEYjixYtIjIykvfee6+CuinqijxzHvO2zgPgtla3EVo/lMxMePppfbxpUzh9GsaM0TvYGgxw+a9uiV56SQc6MlVKCCGqRpkDlrFjx5KUlMQrr7xCXFwcHTp0YN26dTRp0gSAuLg4oqOjrfVNJhMLFizg6NGjODo6MmjQILZt20bTAhteXLp0iQcffJD4+Hi8vb3p0qULv//+Oz169Lj2Hoo6Y2v0Vh5d9yj7z+8H4PEejwOwYIGeuxIcDPv2wV13wTq9PQvDh8Plv7olcnCQYEUIIaqSQSmlqroRFcFoNOLt7U1KSorMZ6ljzMrMkz8/yaKdiwCo71Kf129+nSldpxAbC61aQUYGrFihh3bS0/VKnx079A62AwdWbfuFEKIuK+3vd5kzLEJUJ2Zl5sHvH+TjvR9jwMCUrlP49+B/4+umJ3TPnq2DlT59YOxYfY67O2zeDOfOlS67IoQQoupJwCJqLLMy88DaB/gk8hPsDHYs+79l3NXxLuvxvDxYvVq/njdPz1excHSUYEUIIWoSCVhEjWMym1h/cj2L/lzE+pPrsTPYsXz0csZ1GGdTb+9eMBrB21tvDCeEEKLmkoBF1Cif7v2U2b/OJjY1FgB7gz3LRy9nbIexhepu2qSfBw6Ey3sUCiGEqKEkYBE1hlKK6eunY8w24uPqw/hO43kw7EHaNmxbZH1LwGK5F5AQQoiaSwIWUWOcNZ7FmG3Ewc6B6CejcXMs/pbJOTmwdat+LQGLEELUfLLJuKgxDl84DEArn1YlBisAO3fq1UENG0L79pXROiGEENeTBCyixrAELO0atrtq3YLDQcXcl1MIIUQNIgGLqDEOXTgEQDvf0gcsBe+0LIQQouaSgEXUGKXNsGRkwPbt+rXMXxFCiNpBAhZRIyilSh2wbNumJ90GB0OLFpXROiGEENebBCyiRohLiyMlOwV7gz2tfFqVWFfmrwghRO0jAYuoESzZlRYNWuDs4Fxi3fXr9bMMBwkhRO0hAYuoEQ4lXJ5we5XhoN274a+/wMkJhg2rjJYJIYSoDBKwiBqhtPNX3ntPP48ZA35+17tVQgghKosELKJGOJx49YAlMRFWrNCvH3usMlolhBCiskjAIqo9pVSphoQ+/hiysyEsDHr0qKzWCSGEqAwSsIhq73xaAsmZydgZ7Gjt07rIOiYTLFmiXz/2mKwOEkKI2kZufiiqvTtG28H2eOoNXE5Ohiuu3oXr/PgjnDkDPj4wdmzlt1EIIcT1JRkWUa2ZTLDjVx9I9+fijzNo0gRefBGSkvLrHDoEzz+vX0+eDK6uVdNWIYQQ149BKaWquhEVwWg04u3tTUpKCl5eXlXdHFFBzp+HgAAAM75NLpB4xh8ADw945BG9fHn+fMjNhXr1YP9+CAmpyhYLIYQoi9L+fkuGRVRrcXGXX7gn8MaaDXz9NdxwA6Slweuvw6uv6mBlxAgJVoQQojaTgEVUS6nZqXz010eM+/RJXeAZRwf/dtxxh94Y7vvvoXdvaNoUvvoKvvtOghUhhKjNZNKtqDaUUuw4u4OP/vqIVYdWkZ6bDqfvAyAoyI4bAjoBegXQ8OH6IYQQom6QgEVUCyaziRErRvDTiZ+sZa18WhHqfx/rgVtu6Iy95AOFEKLOkp8AUS18tu8zfjrxE872zkzoPIHfJ/3O34/+TXPHfgAEBlZxA4UQQlQpybCIKpeWk8asTbMAmHvjXJ4Kf8p6zDLpVgIWIYSo2yTDIqrc63+8TnxaPM3rN+exHrY3AZKARQghBEjAIqpYTEoMb2x7A4C5/RdgMDvbHJeARQghBEjAIqrY85ueJzMvk74BQ3n57ttp3hwyM/UxpSRgEUIIoUnAIqrMhfQLLN+/HIAWBz/lyBEDZ8/C4cP6eHIy5OTo13q3WyGEEHWVBCyiykScikChaK1uZ/l/81MoR4/qZ0t2pUEDcHGpggYKIYSoNiRgEVXm5xM/g4LsH/5Dbm5++ZUBiwwHCSGEkIBFVAmzMrPh5AY4MprTe1rh7AwPPaSPScAihBDiShKwiCqxL34f59POY4hYAMAzz8Ctt+pjx47pZwlYhBBCWMjGcaJKrD+5HtIbopKbYjDAs89CTIw+duyYrBASQghhSzIsokr8fOJnMAYD4O8P7u7QrBnY20N6OsTGwrlzuq4ELEIIISRgEZUuNTuVP2L+AGMIAME6bsHJSQctoLMskmERQghhIQGLqHSbojaRZ87DN68LACEh+cdat9bPR49KwCKEECKfBCyi0q0/uR6AxoQD+RkWgFat9LMELEIIIQqSgEVUKpPZpOevAF7Z7YCiMyx79ui5LCABixBCCAlYRCWbsX4GUZei8HDyIPeSjkQKZlgsAcuff+pnDw/9EEIIUbdJwCIqzbs732XRzkUAfDryU+Ji7YGiMyyWnW8luyKEEAIkYBGV5MdjPzLt52kAzBs8j9Ft/sHZs/pYwQyLvz94eeW/l4BFCCEESMAiKkFaThr3fHMPZmXm/hvu59k+z5KYqO/EbDBAUFB+XYMhf+It2B4TQghRd0nAIq67307/Rkp2Ck28m7Bk+BIMBoN1V1t/f73/SkGWYSGQDIsQQgitXAHL4sWLCQ0NxcXFhbCwMLZs2VJi/ffee4+2bdvi6upK69at+fzzzwvVWb16Ne3atcPZ2Zl27dqxZs2a8jRNVEPrT+hlzMNaDMPJXkcnluGggvNXLCRgEUIIcaUyByyrVq1i+vTpzJo1i71799KvXz+GDRtGdHR0kfWXLFnCzJkzmTNnDocOHeLll1/m0Ucf5fvvv7fW2b59O2PHjmX8+PHs27eP8ePHM2bMGP60LBURNZpl35WhLYZayywZloLzVywkYBFCCHElg1JKleWEnj170rVrV5YsWWIta9u2LaNGjWLevHmF6oeHh9OnTx/+85//WMumT5/O7t272bp1KwBjx47FaDTy008/Wevccsst1K9fnxUrVpSqXUajEW9vb1JSUvAqOGtTVKmo5CiaLWqGvcGei89exMtZ/9k89xzMnw9PPAFvv217TmQkdNGb4LJxIwweXLltFkIIUXlK+/tdpgxLTk4Oe/bsYciQITblQ4YMYdu2bUWek52djYuLi02Zq6srO3fuJPfy2tXt27cXuubQoUOLvablukaj0eYhqp8NJzcA0DuktzVYgZIzLC1b5r+WDIsQQggoY8CSmJiIyWTC39/fptzf35/4+Pgizxk6dCgfffQRe/bsQSnF7t27+eSTT8jNzSUxMRGA+Pj4Ml0TYN68eXh7e1sfIUVNhhBVzjoc1HyoTXlJc1jc3WHqVBgyxHbFkBBCiLqrXJNuDQaDzXulVKEyi9mzZzNs2DB69eqFo6MjI0eOZNKkSQDY29uX65oAM2fOJCUlxfqIsfyTXVQbuaZcfon6BRRsf2cqDzwAlgHIkjIsAEuWwPr14OBQOW0VQghRvZUpYPH19cXe3r5Q5iMhIaFQhsTC1dWVTz75hIyMDE6fPk10dDRNmzbF09MTX19fAAICAsp0TQBnZ2e8vLxsHqJ62Rm7E2O2kXpZXVj3tS8ffQQHD4LZDLGxuo4kxoQQQpRGmQIWJycnwsLCiIiIsCmPiIggPDy8xHMdHR0JDg7G3t6elStXMnz4cOzs9Mf37t270DU3bNhw1WuK6s0yHHSD8x3Wsu+/hwsXit40TgghhChOmRPuM2bMYPz48XTr1o3evXvzwQcfEB0dzdSpUwE9VBMbG2vda+XYsWPs3LmTnj17kpyczJtvvsnBgwf57LPPrNecNm0a/fv3Z/78+YwcOZLvvvuOjRs3WlcRiZrJErA0Ng2yln3/PQy9PJ0lIAAcHauiZUIIIWqaMgcsY8eOJSkpiVdeeYW4uDg6dOjAunXraNKkCQBxcXE2e7KYTCYWLFjA0aNHcXR0ZNCgQWzbto2mTZta64SHh7Ny5UpeeOEFZs+eTfPmzVm1ahU9e/a89h6KKnEx8yK7YncB4GrsaC3/80/YvVu/Lm7+ihBCCHGlMu/DUl3JPizVy9eHv+bOr+6kfcP2tNp4kIIbF99wg95rZfRoWL26qloohBCiOrgu+7AIUVobT20E4OZmN3PypC7r1Us/R0bqZ8mwCCGEKC0JWMR1YQlYBofeZA1YnnzSto6sEBJCCFFaErCICheVHMXJ5JM42DnQxmUA6elgZwcjR9oGKZJhEUIIUVoSsIgKZ8mu9AruxfmzHoAOVJydYcSI/HqSYRFCCFFaErCICrcxqvD8lebN9XPBgEUyLEIIIUpLNj4XFcqszPxy6hcAbmp2Ez/rl7RooZ8HDdL3BzIYoFGjKmqkEEKIGkcCFlGhIuMjScpMwtPJk+5B3XnvigyLszPs3avvEST3CRJCCFFa8pMhKpRl/srApgNxtHcsNCQE4OZWBQ0TQghRo8kcFlGhCu6/AlgDFsuQkBBCCFEeErCICpOVl8WW6C2Anr+SkgKJifpYs2ZV2DAhhBA1ngQsosL8Ef0HWXlZBHkG0ca3jTW74ucHnp5V2zYhhBA1mwQsosIUHA4yGAxFzl8RQgghykMCFlFhLPuv3NTsJgBOnNDlMn9FCCHEtZKARZTLxlMbOZRwyPo+KSOJPef2ADA4dDCAZFiEEEJUGFnWLMrseNJxhnwxhAauDTgz/QzuTu78evpXFIr2DdsT6BkISMAihBCi4kiGRZTZrnO7UCiSMpP4fN/nQOHlzCBLmoUQQlQcCVhEme0/v9/6euGfCzErszVgscxfycqCs2d1HcmwCCGEuFYSsIgyO5BwwPr6WNIxFu9azMnkkzjYOdC/SX8A/voLlAJfX/0QQgghroUELKLMLBmW3sG9AXg64mkAegX3wtNZb7iyebOu27+/vtGhEEIIcS0kYBFlkpyZzFmjHut5f/j72BnsyMrLAmznr1gClgEDKr2JQgghaiEJWESZHEw4CEBj78Z08u/EHW3vsB6zzF/Jy4M//tBlErAIIYSoCBKwiDKxDAd18u8EwIzeMwBo4NqA7kHdAT1/JS0N6teHjh2rpp1CCCFqF9mHRZSJZcJtRz8difQK7sUPd/2An7sfjvaOQP5wUL9+YCchsRBCiAogAYsoE0uGxRKwANzW6jabOjJ/RQghREWTf/+KUlNKWeewWIaErmQywZYt+rUELEIIISqKBCyi1M6knCE1JxVHO0da+bSylv/0E+zapV/v2wdGI3h5wQ03VE07hRBC1D4yJCRKzTIc1LZhW+t8lePH4bbb9FyVpUvhwgVdt29fsLevooYKIYSodSRgEaV24LyecFtwOOjXX/WOtiYTjB8PjRrpchkOEkIIUZFkSEiU2v6EwhNuLfNVmjbVz7Gx+lkCFiGEEBVJAhZRLJPZxJzf5vD2jrdJzky2ZlgKBiy//66fP/gAXnlFv27QALp2rezWCiGEqM0MSilV1Y2oCEajEW9vb1JSUvDy8qrq5tQK22O2E/5JOACuDq5k5WWhUJx98iyNvBpx5ozOrNjbw6VL4OEBmzaBjw907lylTRdCCFFDlPb3W+awiGLFpurxHQMGMvMyAfBx9SHIMwjIHw7q2lUHKwA33ljpzRRCCFEHyJCQKNb5tPMAjGozij/u/4OBF1bxhN8aDJdvv2wJWPr3r6oWCiGEqCskwyKKdT5dByz+7v64JYXz23uw0w0evAUCAvIDln79qrCRQggh6gTJsFzFuHHQsiX89ltVt6TyWTIs/h7+nDihyzIy4NVX9X4rR47osr59q6iBQggh6gzJsFxFTAycOAEXL1Z1SypfwQxLzN788g8+gGbN9Ov27fUkWyGEEOJ6kgzLVbi56efMzKptR1WwBiwe/sTE5Jfn5sJzz+nXMn9FCCFEZZCA5SpcXfVznQxY0gpkWC4HLOPH6+fcXP0s81eEEEJUBglYrsISsGRkVG07qkJRGZZRo+COO/LrSMAihBCiMkjAchV1dUgoPSedjFwdpRXMsISEwL/+Be7u0L07BAdXYSOFEELUGTLp9irq6pCQJbvi6uCKs8GDuDhdHhKilzSfOKGDFiGEEKIySMByFXV1SKjgkua4OANKgaMj+Pnp4wEBVdg4IYQQdY4MCV1FXR0SslnSfHk4KDgY7ORvjBBCiCogPz9XUWeHhNIKT7gNCanCBgkhhKjTJGC5ijo7JFQgwxIdrcskYBFCCFFVJGC5ijo7JFTEHiyNG1dhg4QQQtRp5QpYFi9eTGhoKC4uLoSFhbHFche8YixfvpzOnTvj5uZGYGAg9913H0lJSdbjS5cuxWAwFHpkZWWVp3kVqs4OCRWxB4tkWIQQQlSVMgcsq1atYvr06cyaNYu9e/fSr18/hg0bRrRl3OAKW7duZcKECUyePJlDhw7x1VdfsWvXLqZMmWJTz8vLi7i4OJuHi4tL+XpVgWRISAIWIYQQVa/MAcubb77J5MmTmTJlCm3btmXhwoWEhISwZMmSIuvv2LGDpk2b8sQTTxAaGkrfvn156KGH2L17t009g8FAQECAzaM6qOtDQn7ufhKwCCGEqHJlClhycnLYs2cPQ4YMsSkfMmQI27ZtK/Kc8PBwzp49y7p161BKcf78eb7++mtuu+02m3ppaWk0adKE4OBghg8fzt69e4u8nkV2djZGo9HmcT3U9SEhb/sAEhN1mQQsQgghqkqZApbExERMJhP+/v425f7+/sTHxxd5Tnh4OMuXL2fs2LE4OTkREBBAvXr1eOedd6x12rRpw9KlS1m7di0rVqzAxcWFPn36cPz48WLbMm/ePLy9va2PkOv0a1oXh4Sy8rIwZusAMO+SznS5uUH9+lXZKiGEEHVZuSbdGgwGm/dKqUJlFocPH+aJJ57gxRdfZM+ePfz8889ERUUxdepUa51evXpx77330rlzZ/r168eXX35Jq1atbIKaK82cOZOUlBTrI8YyblHB6uKQ0Nr1l8AYhJO9EykJXoDOrhTzRyyEEEJcd2Xamt/X1xd7e/tC2ZSEhIRCWReLefPm0adPH55++mkAOnXqhLu7O/369ePVV18lMDCw0Dl2dnZ07969xAyLs7Mzzs7OZWl+udS1IaEDB2Ds8ADwjaDhc7dw9qyOUmQ4SAghRFUqU4bFycmJsLAwIiIibMojIiIIDw8v8pyMjAzsrtjP3d7eHtCZmaIopYiMjCwymKlsdW1I6NChyy8S2+F2drhMuBVCCFEtlPnmhzNmzGD8+PF069aN3r1788EHHxAdHW0d4pk5cyaxsbF8/vnnAIwYMYIHHniAJUuWMHToUOLi4pg+fTo9evQgKCgIgJdffplevXrRsmVLjEYjixYtIjIykvfee68Cu1o+liGh3FwwmeByrFVrWe7KDJD6x93EdNGvJWARQghRlcocsIwdO5akpCReeeUV4uLi6NChA+vWraNJkyYAxMXF2ezJMmnSJFJTU3n33Xd56qmnqFevHjfeeCPz58+31rl06RIPPvgg8fHxeHt706VLF37//Xd69OhRAV28NpYMC+hhIQ+PqmtLZSgYsJzf05udufq1BCxCCCGqkkEVNy5TwxiNRry9vUlJScHLy6vCrms252dVzp8HP78Ku3S1NH48LFtWuHz9erhiNbsQQghxzUr7+y33EroKOzuwbLh7KiGO5fuXFzv3pqaJNcaSnZdtU3bu3OUXzX+2KZcMixBCiKokAUspWIaFJnz1EPeuuZeIUxEln1ADHDh/gMYLGzP6y9E25dYhoZ7v4FEvP5iRgEUIIURVkoClFCwBy/H4swDEpFyfPV8q05boLZiVmXXH1/Fr1K/WcmvAUi+KW+/Uy9fr1av9c3eEEEJUbxKwlIKb2+UhoDwduaTmpFZhayrGsaRj1tcv/vYiSikyM+HSpcuFnnFMfjAbX18YNqxKmiiEEEJYlXmVUF1kdsgA3CFXr3FOza5dAcvW6K1sPLWRFnY36wL7LHC5RNd2DYiNBSenKmqkEEIIcZlkWEohKVcPBRny3AGs99mpySwBS1hgGKCzLOfOXc4kecZhb2dPA9cGEqwIIYSoFiRguYp98ftIMemlM30DdQaipg8J5ZhyiLoUBcAHIz7A1cGVHWd38PrPX+gKHnE0dG+InUH+egghhKge5BfpKub/MR8c9I2EglxaADU/YIlKjsKszLg7utMloAuPdH8EgLV7duoKnnF09OtYhS0UQgghbEnAUoJcUy6nkk+Bow5Y7E16SKimz2GxDAe18mmFwWBgZt+Z3NbyNpo79gdg6A2dWD1mdVU2UQghhLAhAUsJHO0d2T55O8PaDgTAYKodc1gKBiwAPm4+/HD3D/RrMAaA/h1a4unsWWXtE0IIIa4kActVGAwGgn189OvcyxmWGj4kZAlYWjZoaVNu2YOlGtwkWwghhLAhAUspWG+AmKv36K/xQ0IXbTMsFhKwCCGEqK4kYCkFN739CsoSsNSSDIsELEIIIWoKCVhKwZJhMeU4AzUjw5KXV3R5Wk4a51L1Mu2WPvlDQrm5cOGCfi0BixBCiOpGApZSuDJgSc9Nx2Q2VWGLShYZqe//M29e4WMnLp4AwNfNl7zUBuTk6PLz5/WzgwP4+lZKM4UQQohSk4ClFCxDQnk5jtaytJy0KmrN1f3xB6Snw8aNhY9ZhoP8EsYQHAyTJulyy3CQvz/Yyd8KIYQQ1Yz8NJWCJcOSnWmHg52+/VJ1nseSkqKfL14sfOxY0jEwG4hf/Qy5ubB6tQ5uzulRIoKCKq+dQgghRGlJwFIKloAlM9OAp5Pen6Q6z2Ox3HE5ObnwsWNJx2D/vVyMagJATg78+qtMuBVCCFG9ScBSCpYhocxM8HL2Aqr35nGWDEtRAcvfcWdg01wALm8vw08/ScAihBCiepOApRQsGZaMDKw7wFbnISFLhsVoLLxa6OD3N4ExhMBGOSxerMskYBFCCFHdScBSCvlDQtSIISFLhgXygxeAY9EXydw0DYBX5ypuvRWcnCAqCjZv1nUkYBFCCFEdScBSCgWHhGpShgVsh4W++O4c5Hjh4H+USeOd8fCAfv30sWN68ZAELEIIIaolCVhKoeCQkGUOS03JsFgCll9O/cKbG5cB4B+aaF26fOuttudKwCKEEKI6koClFIoaEqrOk24LZlguXlQs+nMRQ5cNJSNFd2Rw+87W48OG2Z4ry5qFEEJURxKwlELBISEPx+o/JFQww7Jm72am/TwNkzLR2rUPAE2CPKzH27SBJnqFMwYD+PlVZkuFEEKI0pGApRSsd2sGXA31geo7JJSTowMri893fA/AC/1eoLPXYMB2632DIT/L4uent+YXQgghqhsJWEqhYMDioi4HLNU0w1IwuwKQleZC96DuvDTwJRITDUDhewWNGqWfW7e+/u0TQgghykP+PV0Kjo4685CXlx+wVNc5LAXnrwAYsnz4+PaPcbBzsN6N+cqAZehQWLMGOnSolCYKIYQQZSYBSym5ukJqKjiavYGak2Hp7DWQjv4dAUhM1GUNGxY+z5JlEUIIIaojGRIqJcuwkKO5ei9rvjLD0thZrwhSKj9guTLDIoQQQlR3ErCUkmWlkIO5eq8SujLDknLJHtDZodxcXWa5h5AQQghRU0jAUkqWDIt9XvXemt+aYbHPAuDiRf3Wkl1xc8sPvoQQQoiaQgKWUrIELHZ57kB1nnSr9It6p4H8nW5lOEgIIURNJgFLKVmyEgaTfpGak4pSqgpbVLTYC+n6Rf0zgAQsQgghagcJWErJkmFROfqFWZnJzMss4YyqERWvx4C8/ZMASE/Xm8lJwCKEEKImk4CllCwBiznXGQN6A7bqOI8lNiENgEaNTRh0M0lOptg9WIQQQoiaQAKWUrIMCWVn2eHhpO/FUx3nsSRczAagaYA33nrLGJKTJcMihBCiZpOApZQsGZaMDPB0rr5Lmy8m63k1LYJ8qa835bUJWIraNE4IIYSo7iRgKSVLwJKZCZ5O1XNps1KK9FS970q74EY0aKDLJcMihBCippOApZQsQ0KZmdU3wxJjjMGcqXfibRcSZM2wXLwoAYsQQoiaTQKWUio4JOTlXD235z+YcBCy9MQV3waORQ4JScAihBCiJpKApZSKGhKqbpNuD54/BNk6YKlXDwlYhBBC1BoSsJRSTRgSiow5AUrPYfH2xjqHJTExf4t+CViEEELURBKwlJLNKqFqOun2wJkYABwczbi65mdYTp0Cs1m/lhsfCiGEqIkkYCmlgkNC1jks1SjDYjKbOH4uAQBPL4XBkB+wHDumn729wdGxihoohBBCXAMJWErJZkioGs5hiboURXaaCwA+9fUfqyVgiYrSzzIcJIQQoqYqV8CyePFiQkNDcXFxISwsjC1btpRYf/ny5XTu3Bk3NzcCAwO57777SEpKsqmzevVq2rVrh7OzM+3atWPNmjXladp1U903jjuYcNA64dbbW+/Jb5nDkpenn2XTOCGEEDVVmQOWVatWMX36dGbNmsXevXvp168fw4YNIzo6usj6W7duZcKECUyePJlDhw7x1VdfsWvXLqZMmWKts337dsaOHcv48ePZt28f48ePZ8yYMfz555/l71kFq+4bx/147EfIqgfoFUKQn2GxkAyLEEKImqrMAcubb77J5MmTmTJlCm3btmXhwoWEhISwZMmSIuvv2LGDpk2b8sQTTxAaGkrfvn156KGH2L17t7XOwoULufnmm5k5cyZt2rRh5syZDB48mIULF5a7YxWt4JBQdZvDkpmbyZeHv7TuwWK5h5AELEIIIWqLMgUsOTk57NmzhyFDhtiUDxkyhG3bthV5Tnh4OGfPnmXdunUopTh//jxff/01t912m7XO9u3bC11z6NChxV4TIDs7G6PRaPO4noocEqomGZa1R9dizDZSj6aAZFiEEELUPmUKWBITEzGZTPj7+9uU+/v7Ex8fX+Q54eHhLF++nLFjx+Lk5ERAQAD16tXjnXfesdaJj48v0zUB5s2bh7e3t/UREhJSlq6UWXXeOO6zfZ8B0NazN5CfYfHyAnv7/HoSsAghhKipyjXp1mAw2LxXShUqszh8+DBPPPEEL774Inv27OHnn38mKiqKqVOnlvuaADNnziQlJcX6iImJKU9XSq26bhwXnxbP+pPrAWjs3BHIz7AYDPmvQQIWIYQQNZdDWSr7+vpib29fKPORkJBQKENiMW/ePPr06cPTTz8NQKdOnXB3d6dfv368+uqrBAYGEhAQUKZrAjg7O+Ps7FyW5l8TS4YlLw9cDNVnSOh/B/6HWZnpFdwLjtQD8jMsoIeFLAuyJGARQghRU5Upw+Lk5ERYWBgRERE25REREYSHhxd5TkZGBnZ2th9jf3mcQikFQO/evQtdc8OGDcVesypYAhYAR7OedJttyibHlFNFLdIsw0ETO0/k0iVdVjCrUnAeiwQsQgghaqoyZVgAZsyYwfjx4+nWrRu9e/fmgw8+IDo62jrEM3PmTGJjY/n8888BGDFiBA888ABLlixh6NChxMXFMX36dHr06EFQUBAA06ZNo3///syfP5+RI0fy3XffsXHjRrZu3VqBXb02Li75rx3MntbXqdmp+LhVzX73++L3sf/8fpzsnRjTfgyfpejyghkWy14sIAGLEEKImqvMAcvYsWNJSkrilVdeIS4ujg4dOrBu3TqaNGkCQFxcnM2eLJMmTSI1NZV3332Xp556inr16nHjjTcyf/58a53w8HBWrlzJCy+8wOzZs2nevDmrVq2iZ8+eFdDFimEw6CxLZibkZDng4uBCVl4WqTlVF7B8c+QbAIa3Gk4D1waSYRFCCFFrGZRlXKaGMxqNeHt7k5KSgpeX13X5DB8ffdfjQ4dg4I9+XMi4wP6p++no3/G6fN7V9P2kL3/E/MGHIz5kStcpBAVBXBz89Rd06aLrPPIILFkCdnaQm6ufhRBCiOqitL/f8vNVBtVp87i0nDT+jNU7AQ8OHQxQYobFx0eCFSGEEDWX/ISVQXXaPG7LmS3kmfNoWq8pofVDycnRgRQUPYdFhoOEEELUZBKwlEF12jxuU9QmAG5seiMAKSn5xwpm1CRgEUIIURtIwFIGBYeEvF10GuNS1qUqacum0zpgGdxMDwdZAhYPD3AoMJV6yBDo3RsefLCyWyiEEEJUnDKvEqrLPDz0s9EIvl46ZZGUmVTp7biYeZG9cXsBGNR0EFD0/BWARo2ghFsyCSGEEDWCZFjKwDKscuEC+LjqpcxJGZUfsPx2+jcUinYN2xHoGQjkZ1gKzl8RQgghagsJWMqgYUP9bBOwVFKGxWQ2WV//cuoXIH/+ChSfYRFCCCFqAwlYyqBgwOLrptMtiRmJ1/1zfz7xMx7zPLj3m3u5mHmx0PwVyA9YJMMihBCiNpI5LGVgk2Fxq7wMS8TJCLLyslh+YDkbT23kfPp57Ax2DGgywFrnwAH9HBp63ZsjhBBCVDrJsJRBkUNClTCH5VzaOQAc7Rw5n34egK6BXanvmr/vvmVibZ8+1705QgghRKWTgKUMqmpIKNYYC8B/h/+XGb1m4GTvxMTOE63HMzNhr140RO/e1705QgghRKWTIaEy8PPTzwWHhJKzkjErM3aG6xf7nUvVGZYWDVpwX5f7mH/zfBzs8v/odu+GvDwIDITL96AUQgghahXJsJSBJcOSkgIe9noLWbMyX9fN45RSxKbGgoJGXo0AbIIVyB8OCg/Xd5UWQgghahsJWMqgfn2wt9evjclO1hsgXs9hoUtZl8jaeTe8lsyGr4OLrFMwYBFCCCFqIwlYysDOTt/1GCpv4u3ij9Jh7YeQXY9XXnIiO9v2uFISsAghhKj9JGApo8pc2rxyJbw4vRFgB3Z5xMXBsmW2dU6cgMREcHaGLl2uSzOEEEKIKicBSxkVtbT5egwJbdsG994LZrMBwv5LqzGfAvCf/4DZnF9v+3b93K2bDlqEEEKI2kgCljIqamnz9RgSWrsWTCZo1es43PYwPW6PxNsbjh6F77/Pr2cZDpLlzEIIIWozCVjKqLLuJ2Q06mfP0GNgp2jq34CHH9Zlr7+eX0/mrwghhKgLJGApo6LmsFyPISFLwJJplwDoJc1PPAFOTjpI+fxzOHcODh7U9STDIoQQojaTgKWMihwSug4ZltRU/ZxGHABBnkEEBsLEyxvcTpwIwcF6lVCzZhAQUOFNEEIIIaoN2em2jCrrfkKWgMXIWQAaeepN415/XQcp69dDTIyuc/PNFf7xQgghRLUiAUsZVdaQkCVgSVGXA5bLu9zWqwcffqiDltOn4dAh6N+/wj9eCCGEqFYkYCmjyh4SUk4p2BvsaejW0Oa4wQChofohhBBC1HYyh6WMLAHLxYtQzyl/SEgpVaGfYwlYcEol0DMQezv7Cr2+EEIIUZNIwFJGlq35lQIy9Ztccy6pOanFn1QOllVCOKda568IIYQQdZUELGXk4AAN9I2aSb/khquDK1CxE2/NZkhLu/zG2UiQZ1CFXVsIIYSoiSRgKYfrfT+h9PQCb5wkwyKEEEJIwFIO1/t+Qpb5KwY7MzhmSoZFCCFEnScBSzn4+ennhITrcz8hS8Bi75IBhvwlzUIIIURdJQFLOVzvIaGCK4QAGRISQghR50nAUg6VNSRkdkoBkCEhIYQQdZ4ELOVQ5OZxFTgkZFnSbHa8BMiQkBBCCCEBSzkUeT+h6zEk5JyKu6M7nk6eFXZtIYQQoiaSgKUcrvf9hArOYWnk1QiDwVBh1xZCCCFqIglYyuF630+oYIZFJtwKIYQQErCUiyVgSUqC+s759xOqKAUzLDLhVgghhJCApVx8dVIFkwkccnT0UpFDQilGk37hbKSzf+cKu64QQghRU0nAUg5OTuDtrV+b03SGJTMvk8zczAq5/p6oEwC4eZiZ2m1qhVxTCCGEqMkkYCkny7BQZooHDnYOQMXMY8nMzeSvM8cBGNauD57OskJICCGEkIClnCwBS2KioUI3j3tn5ztkpesA6Jb2fa/5ekIIIURtIAFLOQVdngsbE1Nge/5STrw1mU2cSj5FnjnPpvxi5kVe2/oa5OisSoN6jhXXYCGEEKIGc6jqBtRUzZvr55Mnwbdr2ZY2L/pzETM2zMDXzZc72t5B/yb9iTgVwTdHvsGYbcTZ1JBswFNGg4QQQghAApZyKxiwNOyrx4fi0+JLde7mM5sBPYT03z3/5b97/ms91ti7Mbn2jYkDvLwqtMlCCCFEjSUBSzkVDFhu8QoGINYYW6pzoy5FAfBi/xc5l3qOned20iekD3d1uIs+jfvQ8F96pE4yLEIIIYRWrjksixcvJjQ0FBcXF8LCwtiyZUuxdSdNmoTBYCj0aN++vbXO0qVLi6yTlZVVnuZVCkvAEhUFjdwbAxBjjLnqeUopTl86DcC4DuP48PYP2Td1H4tvW0y/Jv2wM9hZN46TgEUIIYTQyhywrFq1iunTpzNr1iz27t1Lv379GDZsGNHR0UXWf/vtt4mLi7M+YmJiaNCgAXfeeadNPS8vL5t6cXFxuLi4lK9XlSAkBBwdIScH3LJaAnDWePaq513KuoQxW9+OuUm9JoWOZ2dDbq5+LQGLEEIIoZU5YHnzzTeZPHkyU6ZMoW3btixcuJCQkBCWLFlSZH1vb28CAgKsj927d5OcnMx9991nU89gMNjUCwgIKF+PKom9PTRtql+bL4YCpcuwWIaD/N39cXN0K3Tcui0/4OFxzc0UQgghaoUyBSw5OTns2bOHIUOG2JQPGTKEbdu2leoaH3/8MTfddBNNmthmF9LS0mjSpAnBwcEMHz6cvXv3lqVpVcIyLJSREAjoOSxmZS7xHMtwUNN6TYs8bglY3NzAQWYYCSGEEEAZA5bExERMJhP+/v425f7+/sTHX32FTFxcHD/99BNTpkyxKW/Tpg1Lly5l7dq1rFixAhcXF/r06cPx48eLvVZ2djZGo9HmUdksAUvS2XoYMJBrzuVC+oUSz4lK1hmW0PqhRR6X+StCCCFEYeWadGswGGzeK6UKlRVl6dKl1KtXj1GjRtmU9+rVi3vvvZfOnTvTr18/vvzyS1q1asU777xT7LXmzZuHt7e39RESElKerlwTS8ByOsqeQE+dZbnasJA1w+LdtMjjErAIIYQQhZUpYPH19cXe3r5QNiUhIaFQ1uVKSik++eQTxo8fj5OTU8mNsrOje/fuJWZYZs6cSUpKivURE3P1+SMVrVkz/XzyJARfXtp8tYm3p1NOA8VnWCyJIglYhBBCiHxlClicnJwICwsjIiLCpjwiIoLw8PASz928eTMnTpxg8uTJV/0cpRSRkZEEBgYWW8fZ2RkvLy+bR2UruBdLsKfO8BQXsBw5AtOmwZGDerv9q81hkYBFCCGEyFfmaZ0zZsxg/PjxdOvWjd69e/PBBx8QHR3N1KlTAZ35iI2N5fPPP7c57+OPP6Znz5506NCh0DVffvllevXqRcuWLTEajSxatIjIyEjee++9cnarclgyLCkp4GtoBUBMStGZngUL4OOPAbtV0Pc1AqfIHBYhhBCitMocsIwdO5akpCReeeUV4uLi6NChA+vWrbOu+omLiyu0J0tKSgqrV6/m7bffLvKaly5d4sEHHyQ+Ph5vb2+6dOnC77//To8ePcrRpcrj5gaBgRAXB87GdgCcTS06w5KQcPmF2RF+n80/Bpv5bCn06mVbzxKwyLb8QgghRL5yLZx95JFHeOSRR4o8tnTp0kJl3t7eZGRkFHu9t956i7feeqs8TalyzZvrgIWLenyouAzLxYuXX3T5CLsTIzh21J++fWHWLHjhBb0JHUiGRQghhChKuVYJiXyWeSyZCUFA8XNYkpMvv+j4P7rPncTdd4PJBK+8An365GdgJGARQgghCpOA5RpZApZLcT4AxKYWvXmcNWBxvUiLRj4sXw4rVkC9erBrFyxcqA/LKiEhhBCiMAlYrpElYImPdsOAgRxTTpGbx1mHhFyTrSuExo2DuXN18f79+lkyLEIIIURhErBcI0vAcuqUHQEe+v5HVw4LZWbqmxoC4JJMaL38FUKWm1YfPqyfZdKtEEIIUZgELNfIErCcOweNXFsAhQMW63CQXR44p9rswdJOLy7i9GnIyJAMixBCCFEUCViukY9PfjakXmZXoPD2/NbhIJdkMNjuctuwIfj6glJw9KgELEIIIURRJGC5RgZDfpbFJfXyXizFZVhckrEz2BHiZXvfI0uW5fBhCViEEEKIokjAUgEu75mHY5re+vbKDEvBFULBXsE42jvaHC8YsMgqISGEEKIwCVgqgI9e0YxDth9QOMNS1AqhgiTDIoQQQpRMApYKYAlY7DL1i5KGhIoKWNq21c8HD0J6un4tq4SEEEKIfBKwVIAGDfRzXoY3oAOWgpvHFRwSaurdtND5lgzLiRP5ZZJhEUIIIfJJwFIBLAFLpjF/87jEjETr8YJDQsFewYXODwwEb+/89w4O4Ox8HRsshBBC1DDluvmhsGUZErqUrDePi0uL46zxLH7uek5LwSGhAI8bCp1vMOgsy/bt+r2npy4TQtQdZrOZrKysqm6GEBXOyckJB4drDzckYKkAlgzLxYsQ7BVMXFocMSkxdA3sai0HwPWidTfcK10ZsAgh6o7s7GwOHz6M2Vz4PmRC1Aa+vr40btwYwzX8a1wClgpgCViSkqCtVzC7zu2yWdqcnKwAA7gmlxiwWMiEWyHqDqUUp0+fxsHBgdDQUOzsZKRe1B5ms5m0tDRiY2MBaGLZB6QcJGCpAJYhoYsXoZGnnqMSa4y1Hk+8aAbswfWidZjoSgUDFsmwCFF35ObmkpaWRmhoKB4eHlXdHCEqnOXvdWxsLM7OzgQEFP0P96uRUL4CWDIsJhP42utt92NT8wOWixcVAF71zDg7FD2bVgIWIeqmvLw8AJxlpr2oxSxByy+//MK5c+fKdQ0JWCqAqyu4uOjXnqamQH7AohSkXNJfs7+vU7HXCAkByz+uJGARou65lrF9Iao7y1DnpUuX+Pnnn8nJySn7NSq6UXWVZVjI3aTvE2TZPC4tDcwm/TUH+bkUe77BkL+BnAQsQgghaqP69euTkpJCqmVb9zKQgKWCWIaFnHMCAT2HRSmVv0LIPovgBj4lXsMyLCQBixCiLho4cCDTp08vdf3Tp09jMBiIjIy8bm0SFcvOzg6z2WwdCi0LmXRbQSwBiyHTF4D03HSM2UaSky/vCFfCCiGLsWNhwwYYNux6tlQIIa7N1YavJk6cyNKlS8t83W+++QZHR8erV7wsJCSEuLg4fH19y/xZouaRgKWCWAKWdKMz9V3qk5yVzFnj2QIBS/F7sFgMGwblnIskhBCVJi4uzvp61apVvPjiixw9etRa5urqalM/Nze3VIFIA8t/SEvJ3t6+3CtOarqcnBycnIqfF1kbyZBQBbFZ2uzVCNATb61DQi5Xz7AIIURNEBAQYH14e3tjMBis77OysqhXrx5ffvklAwcOxMXFhWXLlpGUlMRdd91FcHAwbm5udOzYkRUrVthc98ohoaZNm/Lvf/+b+++/H09PTxo3bswHH3xgPX7lkNBvv/2GwWDgl19+oVu3bri5uREeHm4TTAG8+uqr+Pn54enpyZQpU3juuee44YYbiu2vyWRi8uTJhIaG4urqSuvWrXn77bcL1fvkk09o3749zs7OBAYG8thjj1mPXbp0iQcffBB/f39cXFzo0KEDP/zwAwBz5swp9PkLFy6kadOm1veTJk1i1KhRzJs3j6CgIFq1agXAsmXL6NatG56engQEBHD33XeTkJBgc61Dhw5x22234eXlhaenJ/369ePkyZP8/vvvODo6Eh8fb1P/qaeeon///sV+H1VFApYKUnDzuEaeOmDRGZbLFUoxJCSEEEop0nPSq+ShlKqwfjz77LM88cQTHDlyhKFDh5KVlUVYWBg//PADBw8e5MEHH2T8+PH8+eefJV5nwYIFdOvWjb179/LII4/w8MMP8/fff5d4zqxZs1iwYAG7d+/GwcGB+++/33ps+fLlzJ07l/nz57Nnzx4aN27MkiVLSrye2WwmODiYL7/8ksOHD/Piiy/y/PPP8+WXX1rrLFmyhEcffZQHH3yQAwcOsHbtWlq0aGE9f9iwYWzbto1ly5Zx+PBhXnvtNezt7a/2Ndr45ZdfOHLkCBEREdZgJycnh3/961/s27ePb7/9lqioKCZNmmQ9JzY2lv79++Pi4sKmTZvYs2cP999/P3l5efTv359mzZrxxRdfWOvn5eWxbNky7rvvvjK1rTLIkFAFuXJ7ftATb10K3Kk5wCOsahonhKgxMnIz8JhXNRvIpc1Mw93JvUKuNX36dEaPHm1T9s9//tP6+vHHH+fnn3/mq6++omfPnsVe59Zbb+WRRx4BdBD01ltv8dtvv9GmTZtiz5k7dy4DBgwA4LnnnuO2224jKysLFxcX3nnnHSZPnmz9QX7xxRfZsGEDaWlpxV7P0dGRl19+2fo+NDSUbdu28eWXXzJmzBhAZ22eeuoppk2bZq3XvXt3ADZu3MjOnTs5cuSINTPSrFmzYj+vOO7u7nz00Uc2Q0EFg7FmzZqxaNEievToQVpaGh4eHrz33nt4e3uzcuVK67CcpQ0AkydP5tNPP+Xpp58G4McffyQjI8Par+pEMiwVxHa32/whoQuJJn1AhoSEEHVIt27dbN6bTCbmzp1Lp06d8PHxwcPDgw0bNhAdHV3idTp16mR9bRl6unLIo6RzAgP1yk3LOUePHqVHjx429a98X5T333+fbt260bBhQzw8PPjwww+tbU9ISODcuXMMHjy4yHMjIyMJDg62CRTKo2PHjoXmrezdu5eRI0fSpEkTPD09GThwIIC1bZGRkfTr16/YOUSTJk3ixIkT7NixA9DDWmPGjMHdvWIC14okGZYKYjMk5JU/JFT/QibggZ1bCg1cyzahTAhR97g5upE2s/h/7V/vz64oV/7gLViwgLfeeouFCxfSsWNH3N3dmT59+lU3ELvyh9ZgMFz1JpEFz7GsaCp4zpWrnK42FPbll1/y5JNPsmDBAnr37o2npyf/+c9/rMNZV04yvtLVjtvZ2RVqQ25ubqF6V36n6enpDBkyhCFDhrBs2TIaNmxIdHQ0Q4cOtX6vV/tsPz8/RowYwaeffkqzZs1Yt24dv/32W4nnVBUJWCpIkUNCqbFkX9B/aTy987AzSEJLCFEyg8FQYcMy1cmWLVsYOXIk9957L6ADiOPHj9PWsmNmJWndujU7d+5k/Pjx1rLdu3eXeM6WLVsIDw+3Dk0BnDx50vra09OTpk2b8ssvvzBo0KBC53fq1ImzZ89y7NixIrMsDRs2JD4+HqWUNZgqzd4yf//9N4mJibz22muEhIQU2ZdOnTrx2WeflbhSa8qUKYwbN47g4GCaN29Onz59rvrZVUF+QStIkUNCxlgSL+ohofr1q6plQghR9Vq0aEFERATbtm3jyJEjPPTQQ4VWp1SGxx9/nI8//pjPPvuM48eP8+qrr7J///4S95Zp0aIFu3fvZv369Rw7dozZs2eza9cumzpz5sxhwYIFLFq0iOPHj/PXX3/xzjvvADBgwAD69+/PHXfcQUREBFFRUfz000/8/PPPgF4ddeHCBV5//XVOnjzJe++9x08//XTVvjRu3BgnJyfeeecdTp06xdq1a/nXv/5lU+exxx7DaDQybtw4du/ezfHjx/niiy9sVk4NHToUb29vXn311Wo52dZCApYKUjDDEnQ5YLmQcYGkyzc+9PUp22xwIYSoTWbPnk3Xrl0ZOnQoAwcOJCAggFGjRlV6O+655x5mzpzJP//5T7p27WpdVePiUvytU6ZOncro0aMZO3YsPXv2JCkpySbbAnqzvIULF7J48WLat2/P8OHDOX78uPX46tWr6d69O3fddRft2rXjmWeewWTS/6Bt27Ytixcv5r333qNz587s3LnTZoJycRo2bMjSpUv56quvaNeuHa+99hpvvPGGTR0fHx82bdpEWloaAwYMICwsjA8//NAm22JnZ8ekSZMwmUxMmDChVN9jVTCoilzHVoWMRiPe3t6kpKTg5eVV6Z+fmQlul4d/k5MVAe+6km3KxmNJAmnnGzJi/jzWPjOz0tslhKjeMjIyOHLkCG3btsXNreLmkIjSu/nmmwkICLBZ3lvXPPDAA5w/f561a9del+tb/p4fP36c2NhY7r33Xvz9/YHS/37LHJYK4uqqH5mZkJxsoJFXI04lnyLTqG8Z38hP/kMkhBBVLSMjg/fff5+hQ4dib2/PihUr2LhxIxEREVXdtCqRkpLCrl27WL58Od99911VN6dEMiRUgQptHme2w5Sl91No7C93NBRCiKpmMBhYt24d/fr1IywsjO+//57Vq1dz0003VXXTqsTIkSO5/fbbeeihh7j55purujklkgxLBWrQAGJjC6wUyvIGpWPC0MB6Vds4IYQQuLq6snHjxqpuRrVRXZcwF0UyLBWo0EqhrMtLgxzTCGngX3UNE0IIIWo4CVgqUKHN4zIvByxyHyEhhBDimkjAUoEKbR6XebnA9SL+HpJhEUIIIcpLApYKVNyQkJ2bEQ+nqrmZmRBCCFEbSMBSgYobEnL1zKzCVgkhhBA1nwQsFajgkFCgRyBk6pSLh1fJN/cSQgghRMkkYKlABYeEHO0dcTPpLfq969WKzYSFEKJCDRw4kOnTp1vfN23alIULF5Z4jsFg4Ntvv73mz66o64jKIwFLBSo4JATgmqvv2tzAp4oaJIQQ18GIESOK3Wht+/btGAwG/vrrrzJfd9euXTz44IPX2jwbc+bM4YYbbihUHhcXx7Bhwyr0s8T1JQFLBSo4JJSbC2mH+wIQ2iK7ClslhBAVa/LkyWzatIkzZ84UOvbJJ59www030LVr1zJft2HDhpV2P6WAgACcnZ0r5bOqk5ycmjtFQQKWClQwYPnuO8i+1AAHrySeva991TZMCCEq0PDhw/Hz82Pp0qU25RkZGaxatYrJkyeTlJTEXXfdRXBwMG5ubnTs2JEVK1aUeN0rh4SOHz9O//79cXFxoV27dkXe7+fZZ5+lVatWuLm50axZM2bPnk1ubi4AS5cu5eWXX2bfvn0YDAYMBoO1zVcOCR04cIAbb7wRV1dXfHx8ePDBB0lLS7MenzRpEqNGjeKNN94gMDAQHx8fHn30UetnFeXkyZOMHDkSf39/PDw86N69e6FddrOzs3nmmWcICQnB2dmZli1b8vHHH1uPHzp0iNtuuw0vLy88PT3p168fJ0+eBAoPqQGMGjWKSZMm2Xynr776KpMmTcLb25sHHnjgqt+bxdq1a+nWrRsuLi74+voyevRoAF555RU6duxYqL9hYWG8+OKLxX4f10q25q9AloDFbIbXX9evn3nMh86NZExICFE6SkFGRtV8tpsbGAxXr+fg4MCECRNYunQpL774IobLJ3311Vfk5ORwzz33kJGRQVhYGM8++yxeXl78+OOPjB8/nmbNmtGzZ8+rfobZbGb06NH4+vqyY8cOjEZjoR9nAE9PT5YuXUpQUBAHDhzggQcewNPTk2eeeYaxY8dy8OBBfv75Z2ug4O3tXegaGRkZ3HLLLfTq1Ytdu3aRkJDAlClTeOyxx2yCsl9//ZXAwEB+/fVXTpw4wdixY7nhhhusQcCV0tLSuPXWW3n11VdxcXHhs88+Y8SIERw9epTGjRsDMGHCBLZv386iRYvo3LkzUVFRJCYmAhAbG0v//v0ZOHAgmzZtwsvLiz/++IO8vLyrfn8F/ec//2H27Nm88MILpfreAH788UdGjx7NrFmz+OKLL8jJyeHHH38E4P777+fll19m165ddO/eHYD9+/ezd+9evvrqqzK1rUxULZGSkqIAlZKSUqXtcHVVSv8nRymDQamoqCptjhCimktPT1e7d+9W6enpSiml0tLy/xtS2Y+0tNK3+8iRIwpQmzZtspb1799f3XXXXcWec+utt6qnnnrK+n7AgAFq2rRp1vdNmjRRb731llJKqfXr1yt7e3sVExNjPf7TTz8pQK1Zs6bYz3j99ddVWFiY9f1LL72kOnfuXKhewet88MEHqn79+iqtwBfw448/Kjs7OxUfH6+UUmrixImqSZMmKi8vz1rnzjvvVGPHji22LUVp166deuedd5RSSh09elQBKiIiosi6M2fOVKGhoSonJ6fI41d+f0opNXLkSDVx4kTr+yZNmqhRo0ZdtV1Xfm+9e/dW99xzT7H1hw0bph5++GHr++nTp6uBAwcWW9/y93zFihXqjTfesH6vSpX+97tcQ0KLFy8mNDQUFxcXwsLC2LJlS7F1J02aZE3FFXy0b287TLJ69WratWuHs7Mz7dq1Y82aNeVpWpWzZFkAhg2Dpk2rrClCCHHdtGnThvDwcD755BNAD39s2bKF+++/HwCTycTcuXPp1KkTPj4+eHh4sGHDBqKjo0t1/SNHjtC4cWOCg4OtZb179y5U7+uvv6Zv374EBATg4eHB7NmzS/0ZBT+rc+fOuLu7W8v69OmD2Wzm6NGj1rL27dtjb29vfR8YGEhCQkKx101PT+eZZ56hXbt21KtXDw8PD/7++29r+yIjI7G3t2fAgAFFnh8ZGUm/fv1wdHQsU3+u1K1bt0JlV/veIiMjGTx4cLHXfOCBB1ixYgVZWVnk5uayfPly65/99VLmgGXVqlVMnz6dWbNmsXfvXvr168ewYcOK/Qvy9ttvExcXZ33ExMTQoEED7rzzTmud7du3M3bsWMaPH8++ffsYP348Y8aM4c8//yx/z6qIT4HRn6lTq64dQoiayc0N0tKq5lHW+a6TJ09m9erVGI1GPv30U5o0aWL9kVuwYAFvvfUWzzzzDJs2bSIyMpKhQ4eWetKnUoW3gzBcMV61Y8cOxo0bx7Bhw/jhhx/Yu3cvs2bNKvPEUqVUoWsX9ZlXBg4GgwGz2VzsdZ9++mlWr17N3Llz2bJlC5GRkXTs2NHaPldX1xLbdbXjdnZ2hb6noubUFAzEoHTf29U+e8SIETg7O7NmzRq+//57srOzueOOO0o851qVOWB58803mTx5MlOmTKFt27YsXLiQkJAQlixZUmR9b29vAgICrI/du3eTnJzMfffdZ62zcOFCbr75ZmbOnEmbNm2YOXMmgwcPvup6/OrIkmEJCYFbb63atgghah6DAdzdq+ZRmvkrBY0ZMwZ7e3v+97//8dlnn3HfffdZf+C3bNnCyJEjuffee+ncuTPNmjXj+PHjpb52u3btiI6O5ty5c9ay7du329T5448/aNKkCbNmzaJbt260bNmy0MolJycnTCbTVT8rMjKS9PR0m2vb2dnRqlWrUrf5Slu2bGHSpEn83//9Hx07diQgIIDTp09bj3fs2BGz2czmzZuLPL9Tp05s2bKl2Im9DRs2JC4uzvreZDJx8ODBq7arNN9bp06d+OWXX4q9hoODAxMnTuTTTz/l008/Zdy4cdd9hVeZApacnBz27NnDkCFDbMqHDBnCtm3bSnWNjz/+mJtuuokmTZpYy7Zv317omkOHDi3xmtnZ2RiNRptHdWDp1kMPQYHMoRBC1DoeHh6MHTuW559/nnPnztmsTmnRogURERFs27aNI0eO8NBDDxEfH1/qa9900020bt2aCRMmsG/fPrZs2cKsWbNs6rRo0YLo6GhWrlzJyZMnWbRoUaHpBE2bNiUqKorIyEgSExPJzi68zcQ999yDi4sLEydO5ODBg/z66688/vjjjB8/Hn//8t+4tkWLFnzzzTdERkayb98+7r77bpuMTNOmTZk4cSL3338/3377LVFRUfz22298+eWXADz22GMYjUbGjRvH7t27OX78OF988YV1mOrGG2/kxx9/5Mcff+Tvv//mkUce4dKlS6Vq19W+t5deeokVK1bw0ksvceTIEQ4cOMDrltUkl02ZMoVNmzbx008/XffhIChjwJKYmIjJZCr0B+jv71+qv4hxcXH89NNPTJkyxaY8Pj6+zNecN28e3t7e1kdISEgZenL9/Otf8OGHcHmitRBC1GqTJ08mOTmZm266ybryBWD27Nl07dqVoUOHMnDgQAICAhg1alSpr2tnZ8eaNWvIzs6mR48eTJkyhblz59rUGTlyJE8++SSPPfYYN9xwA9u2bWP27Nk2de644w5uueUWBg0aRMOGDYtcWu3m5sb69eu5ePEi3bt35x//+AeDBw/m3XffLduXcYW33nqL+vXrEx4ezogRIxg6dGih/WmWLFnCP/7xDx555BHatGnDAw88YM30+Pj4sGnTJtLS0hgwYABhYWF8+OGH1qGp+++/n4kTJzJhwgQGDBhAaGgogwYNumq7SvO9DRw4kK+++oq1a9dyww03cOONNxaaptGyZUvCw8Np3bp1qVZ+XSuDKmqgsBjnzp2jUaNGbNu2zWby09y5c/niiy/4+++/Szx/3rx5LFiwgHPnzuHk5GQtd3Jy4rPPPuOuu+6yli1fvpzJkyeTlZVV5LWys7NtImWj0UhISAgpKSl4eXmVtktCCFGlMjIyOHLkCG3btq20TdOEqAhKKdq0acNDDz3EjBkzSqxr+Xt+/PhxYmNjuffee62JCqPRiLe391V/v8u0D4uvry/29vaFMh8JCQlXTZsppfjkk08YP368TbACesfBsl7T2dm5Tu5SKIQQQlS1hIQEvvjiC2JjY23mpF5PZRoScnJyIiwsrNBugxEREYSHh5d47ubNmzlx4gSTJ08udKx3796Frrlhw4arXlMIIYQQlc/f35/XXnuNDz74gPr161fKZ5Z5p9sZM2Ywfvx4unXrRu/evfnggw+Ijo5m6uU1vDNnziQ2NpbPP//c5ryPP/6Ynj170qFDh0LXnDZtGv3792f+/PmMHDmS7777jo0bN7J169ZydksIIYQQ10sZZpNUmDIHLGPHjiUpKYlXXnmFuLg4OnTowLp166yrfuLi4grtyZKSksLq1at5++23i7xmeHg4K1eu5IUXXmD27Nk0b96cVatWVcokHiGEEEJUf2WadFudlXbSjhBCVCcy6VbUBRUx6Vbu1iyEENVASTumClHTWf5+X0uORO7WLIQQVcjZ2RmDwUBcXByBgYHY2cm/I0XtoZQiOzubmJgYzGZzkRv3lZYELEIIUYXs7e1p0aIFJ06cqDY7dgtR0TIzM4mLi8NsNmNnZ1euwFwCFiGEqGJeXl60bNmSb775hqysLHx8fIq9GZ8QNU1eXh4mkwmlFBcvXsTDwwMPD48yX0cCFiGEqAY8PT3p2bMnGzZs4NixYzg6OkrQImoNpRS5ubl4enpy4403XvVu0EWRgEUIIaqJNm3a4OjoyJkzZ0hLS6vq5ghRoTw8PGjatCnNmjUr1/kSsAghRDXSvHlzmjdvXtXNEKLakenoQgghhKj2ak2GxbK2W2bZCyGEEDWH5Xf7anu01JqAJTU1FYCQkJAqbokQQgghyio1NRVvb+9ij9earfnNZjPnzp3D09OzQmfWG41GQkJCiImJqTNb/te1Pte1/kLd63Nd6y/UvT7Xtf5C7emzUorU1FSCgoJK3J+l1mRY7OzsCA4Ovm7X9/LyqtF/IcqjrvW5rvUX6l6f61p/oe71ua71F2pHn0vKrFjIpFshhBBCVHsSsAghhBCi2pOA5SqcnZ156aWXcHZ2ruqmVJq61ue61l+oe32ua/2FutfnutZfqHt9rjWTboUQQghRe0mGRQghhBDVngQsQgghhKj2JGARQgghRLUnAYsQQgghqj0JWK5i8eLFhIaG4uLiQlhYGFu2bKnqJlWIefPm0b17dzw9PfHz82PUqFEcPXrUpo5Sijlz5hAUFISrqysDBw7k0KFDVdTiijVv3jwMBgPTp0+3ltXG/sbGxnLvvffi4+ODm5sbN9xwA3v27LEer019zsvL44UXXiA0NBRXV1eaNWvGK6+8gtlsttap6f39/fffGTFiBEFBQRgMBr799lub46XpX3Z2No8//ji+vr64u7tz++23c/bs2UrsRdmU1Ofc3FyeffZZOnbsiLu7O0FBQUyYMIFz587ZXKMm9flqf8YFPfTQQxgMBhYuXGhTXpP6WxYSsJRg1apVTJ8+nVmzZrF371769evHsGHDiI6OruqmXbPNmzfz6KOPsmPHDiIiIsjLy2PIkCGkp6db67z++uu8+eabvPvuu+zatYuAgABuvvlm632baqpdu3bxwQcf0KlTJ5vy2tbf5ORk+vTpg6OjIz/99BOHDx9mwYIF1KtXz1qnNvV5/vz5vP/++7z77rscOXKE119/nf/85z+888471jo1vb/p6el07tyZd999t8jjpenf9OnTWbNmDStXrmTr1q2kpaUxfPhwTCZTZXWjTErqc0ZGBn/99RezZ8/mr7/+4ptvvuHYsWPcfvvtNvVqUp+v9mds8e233/Lnn38SFBRU6FhN6m+ZKFGsHj16qKlTp9qUtWnTRj333HNV1KLrJyEhQQFq8+bNSimlzGazCggIUK+99pq1TlZWlvL29lbvv/9+VTXzmqWmpqqWLVuqiIgINWDAADVt2jSlVO3s77PPPqv69u1b7PHa1ufbbrtN3X///TZlo0ePVvfee69Sqvb1F1Br1qyxvi9N/y5duqQcHR3VypUrrXViY2OVnZ2d+vnnnyut7eV1ZZ+LsnPnTgWoM2fOKKVqdp+L6+/Zs2dVo0aN1MGDB1WTJk3UW2+9ZT1Wk/t7NZJhKUZOTg579uxhyJAhNuVDhgxh27ZtVdSq6yclJQWABg0aABAVFUV8fLxN/52dnRkwYECN7v+jjz7Kbbfdxk033WRTXhv7u3btWrp168add96Jn58fXbp04cMPP7Qer2197tu3L7/88gvHjh0DYN++fWzdupVbb70VqH39vVJp+rdnzx5yc3Nt6gQFBdGhQ4da8R2A/m+ZwWCwZhJrW5/NZjPjx4/n6aefpn379oWO17b+FlRrbn5Y0RITEzGZTPj7+9uU+/v7Ex8fX0Wtuj6UUsyYMYO+ffvSoUMHAGsfi+r/mTNnKr2NFWHlypX89ddf7Nq1q9Cx2tjfU6dOsWTJEmbMmMHzzz/Pzp07eeKJJ3B2dmbChAm1rs/PPvssKSkptGnTBnt7e0wmE3PnzuWuu+4CauefcUGl6V98fDxOTk7Ur1+/UJ3a8N+1rKwsnnvuOe6++27rzQBrW5/nz5+Pg4MDTzzxRJHHa1t/C5KA5SoMBoPNe6VUobKa7rHHHmP//v1s3bq10LHa0v+YmBimTZvGhg0bcHFxKbZebekv6H+JdevWjX//+98AdOnShUOHDrFkyRImTJhgrVdb+rxq1SqWLVvG//73P9q3b09kZCTTp08nKCiIiRMnWuvVlv4Wpzz9qw3fQW5uLuPGjcNsNrN48eKr1q+Jfd6zZw9vv/02f/31V5nbXhP7eyUZEiqGr68v9vb2hSLShISEQv+Cqckef/xx1q5dy6+//kpwcLC1PCAgAKDW9H/Pnj0kJCQQFhaGg4MDDg4ObN68mUWLFuHg4GDtU23pL0BgYCDt2rWzKWvbtq110nht+zN++umnee655xg3bhwdO3Zk/PjxPPnkk8ybNw+off29Umn6FxAQQE5ODsnJycXWqYlyc3MZM2YMUVFRREREWLMrULv6vGXLFhISEmjcuLH1v2NnzpzhqaeeomnTpkDt6u+VJGAphpOTE2FhYURERNiUR0REEB4eXkWtqjhKKR577DG++eYbNm3aRGhoqM3x0NBQAgICbPqfk5PD5s2ba2T/Bw8ezIEDB4iMjLQ+unXrxj333ENkZCTNmjWrVf0F6NOnT6Gl6seOHaNJkyZA7fszzsjIwM7O9j9p9vb21mXNta2/VypN/8LCwnB0dLSpExcXx8GDB2vsd2AJVo4fP87GjRvx8fGxOV6b+jx+/Hj2799v89+xoKAgnn76adavXw/Urv4WUkWTfWuElStXKkdHR/Xxxx+rw4cPq+nTpyt3d3d1+vTpqm7aNXv44YeVt7e3+u2331RcXJz1kZGRYa3z2muvKW9vb/XNN9+oAwcOqLvuuksFBgYqo9FYhS2vOAVXCSlV+/q7c+dO5eDgoObOnauOHz+uli9frtzc3NSyZcusdWpTnydOnKgaNWqkfvjhBxUVFaW++eYb5evrq5555hlrnZre39TUVLV37161d+9eBag333xT7d2717oipjT9mzp1qgoODlYbN25Uf/31l7rxxhtV586dVV5eXlV1q0Ql9Tk3N1fdfvvtKjg4WEVGRtr8tyw7O9t6jZrU56v9GV/pylVCStWs/paFBCxX8d5776kmTZooJycn1bVrV+uy35oOKPLx6aefWuuYzWb10ksvqYCAAOXs7Kz69++vDhw4UHWNrmBXBiy1sb/ff/+96tChg3J2dlZt2rRRH3zwgc3x2tRno9Gopk2bpho3bqxcXFxUs2bN1KxZs2x+uGp6f3/99dci/387ceJEpVTp+peZmakee+wx1aBBA+Xq6qqGDx+uoqOjq6A3pVNSn6Oioor9b9mvv/5qvUZN6vPV/oyvVFTAUpP6WxYGpZSqjEyOEEIIIUR5yRwWIYQQQlR7ErAIIYQQotqTgEUIIYQQ1Z4ELEIIIYSo9iRgEUIIIUS1JwGLEEIIIao9CViEEEIIUe1JwCKEEEKIak8CFiGEEEJUexKwCCGEEKLak4BFCCGEENWeBCxCCCGEqPb+H3PQFq/YbuziAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "\n",
    "ax1.plot(firstFit.history['acc'], color='g', label=\"Training accuracy\")\n",
    "ax1.plot(firstFit.history['val_acc'], color='b', label=\"Validation accuracy\")\n",
    "\n",
    "#ax[0].plot(firstFit.history['val_loss'], color='r', label=\"Validation Loss\",axes =ax[0])\n",
    "ax1.legend(loc=4, bbox_to_anchor=(0, 0, 1, 1), shadow=True)\n",
    "ax2.legend(loc=4, bbox_to_anchor=(-0.39, 0, 1, 1), shadow=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
